# -*- coding: utf-8 -*-
"""
WS_AUTO_AI — Pernada B (M1) com:
✅ Candles FECHADOS (evita sinal fora da hora)
✅ Anti-lateral + Anti-esticado
✅ Filtro de SUPORTE/RESISTÊNCIA FORTE (usa >=200 velas e considera várias regiões)
✅ IA ENSEMBLE: Bayesiano + LightGBM (Gradient Boosting) para decisões mais inteligentes
✅ Execução real (TURBO -> DIGITAL fallback)

Requisitos:
pip install iqoptionapi pandas numpy lightgbm
"""

import os
import time
import math
import json
import logging
import pickle
from typing import Optional, Dict, Any, List, Tuple

import numpy as np
import pandas as pd

# ===================== MULTI-BROKER SUPPORT =====================
# Detecta qual corretora usar via variável de ambiente BROKER_TYPE
BROKER_TYPE = os.getenv("BROKER_TYPE", "iq_option").lower().strip()

if BROKER_TYPE == "bullex":
    from bullexapi.stable_api import Bullex as BrokerAPI
    _BROKER_NAME = "Bullex"
elif BROKER_TYPE == "casatrader":
    from casatraderapi.stable_api import Casa_Trader as BrokerAPI
    _BROKER_NAME = "CasaTrader"
else:
    from iqoptionapi.stable_api import IQ_Option as BrokerAPI
    _BROKER_NAME = "IQ Option"
    BROKER_TYPE = "iq_option"

# LightGBM para Gradient Boosting
try:
    import lightgbm as lgb
    LGBM_AVAILABLE = True
except ImportError:
    lgb = None
    LGBM_AVAILABLE = False

# ===================== CONFIG =====================
# Credenciais por broker
if BROKER_TYPE == "bullex":
    EMAIL = os.getenv("BULLUX_EMAIL", "") or os.getenv("IQ_EMAIL", "")
    SENHA = os.getenv("BULLUX_PASS", "") or os.getenv("IQ_PASS", "")
    CONTA = os.getenv("BULLUX_CONTA", "PRACTICE")
elif BROKER_TYPE == "casatrader":
    EMAIL = os.getenv("CASATRADER_EMAIL", "") or os.getenv("IQ_EMAIL", "")
    SENHA = os.getenv("CASATRADER_PASS", "") or os.getenv("IQ_PASS", "")
    CONTA = os.getenv("CASATRADER_CONTA", "PRACTICE")
else:
    EMAIL = os.getenv("IQ_EMAIL", "")
    SENHA = os.getenv("IQ_PASS", "")
    CONTA = os.getenv("IQ_CONTA", "PRACTICE")

TF_M1 = 60
DECIDIR_ANTES_FECHAR_SEC = int(os.getenv("WS_DECIDIR_ANTES_FECHAR", "10"))
N_M1 = int(os.getenv("WS_N_M1", "340"))

PAYOUT_MINIMO = int(os.getenv("WS_PAYOUT_MIN", "80"))
NUM_ATIVOS = int(os.getenv("WS_NUM_ATIVOS", "12"))
PAYOUT_REFRESH_SEC = int(os.getenv("WS_PAYOUT_REFRESH", "180"))

EXP_FIXA = int(os.getenv("WS_EXP_MIN", "5"))
VALOR_MINIMO = float(os.getenv("WS_VALOR_MINIMO", "3"))
STAKE_FIXA = float(os.getenv("WS_STAKE", "5"))

# ===================== GESTÃO DE BANCA =====================
PERCENT_BANCA = float(os.getenv("WS_PERCENT_BANCA", "1.0"))  # 1% da banca por operação
META_LUCRO_PERCENT = float(os.getenv("WS_META_LUCRO", "1.5"))  # para com 1.5% de lucro
STOP_LOSS_PERCENT = float(os.getenv("WS_STOP_LOSS", "3.0"))  # para com 3% de perda (opcional)
USE_DYNAMIC_STAKE = (os.getenv("WS_DYNAMIC_STAKE", "1").strip() == "1")  # usar % da banca

COOLDOWN_ATIVO = int(os.getenv("WS_COOLDOWN_ATIVO", "60"))  # 60 seg de cooldown base
COOLDOWN_LOSS_ATIVO = int(os.getenv("WS_COOLDOWN_LOSS", "300"))  # 5 min após LOSS no ativo
MAX_CONSECUTIVE_LOSS = int(os.getenv("WS_MAX_CONSEC_LOSS", "1"))  # Pausa após 1 loss
RETRAIN_ON_LOSS = (os.getenv("WS_RETRAIN_ON_LOSS", "0").strip() == "1")  # DESATIVADO: usar backtest em vez de retreino
BACKTEST_ON_LOSS = (os.getenv("WS_BACKTEST_ON_LOSS", "1").strip() == "1")  # ATIVADO: backtest 30min após LOSS para recalibrar
PAUSE_AFTER_LOSS_SECONDS = int(os.getenv("WS_PAUSE_AFTER_LOSS", "60"))  # Pausa de 1 min após loss antes de continuar
RETRAIN_PENALTY = float(os.getenv("WS_RETRAIN_PENALTY", "0.25"))  # Penalidade ao retreinar padrão

# ===================== IA (ONLINE) - APRENDIZADO ADAPTATIVO =====================
IA_ON = (os.getenv("WS_AI_ON", "1").strip() == "1")  # LIGADO: aprende bloqueando losses
# Arquivos por broker para não conflitar
_broker_suffix = {"iq_option": "m1", "bullex": "bullex", "casatrader": "casatrader"}.get(BROKER_TYPE, "m1")
AI_STATS_FILE = os.getenv("WS_AI_FILE", f"ws_ai_stats_{_broker_suffix}.json")
AI_MIN_SAMPLES = int(os.getenv("WS_AI_MIN_SAMPLES", "15"))   # 15 trades para começar a bloquear
AI_MIN_PROB = float(os.getenv("WS_AI_MIN_PROB", "0.55"))     # probabilidade mínima (bayesiana) - AUMENTADO para 55%
AI_MIN_WINRATE = float(os.getenv("WS_AI_MIN_WINRATE", "0.42"))  # bloqueia se winrate < 42%
AI_CONF_MIN = float(os.getenv("WS_AI_CONF_MIN", "0.50"))     # confiança mínima na decisão

# ===================== LIGHTGBM ENSEMBLE =====================
LGBM_ON = (os.getenv("WS_LGBM_ON", "1").strip() == "1") and LGBM_AVAILABLE  # LightGBM ativo
LGBM_MODEL_FILE = os.getenv("WS_LGBM_FILE", f"ws_lgbm_model_{_broker_suffix}.pkl")
LGBM_DATA_FILE = os.getenv("WS_LGBM_DATA", f"ws_lgbm_data_{_broker_suffix}.json")
LGBM_MIN_SAMPLES = int(os.getenv("WS_LGBM_MIN_SAMPLES", "30"))  # Mínimo de amostras para treinar
LGBM_RETRAIN_EVERY = int(os.getenv("WS_LGBM_RETRAIN", "10"))   # Retreina a cada N trades
LGBM_MIN_PROB = float(os.getenv("WS_LGBM_MIN_PROB", "0.58"))   # Probabilidade mínima do LGBM - balanceado
LGBM_WARMUP_PROB = float(os.getenv("WS_LGBM_WARMUP_PROB", "0.55"))  # Threshold durante warmup (55% - balanceado)
ENSEMBLE_MODE = os.getenv("WS_ENSEMBLE_MODE", "any")  # "any" = qualquer um aprova (menos restritivo)

# ===================== FILTROS DE QUALIDADE ENSEMBLE =====================
# Exigência mínima de ensemble baseada na qualidade do contexto
ENS_MIN_CTX_RUIM = float(os.getenv("WS_ENS_MIN_CTX_RUIM", "0.58"))  # ctx < 0.40 precisa ensemble >= 0.58
ENS_MIN_CTX_MED  = float(os.getenv("WS_ENS_MIN_CTX_MED",  "0.54"))  # ctx 0.40-0.50 precisa ensemble >= 0.54
ENS_MIN_CTX_BOM  = float(os.getenv("WS_ENS_MIN_CTX_BOM",  "0.50"))  # ctx >= 0.50 precisa ensemble >= 0.50

# ===================== MODO DA IA =====================
# "learning" = IA tem controle total, filtros de score relaxados (mais trades, aprende mais rápido)
# "strict"   = IA + filtros rigorosos (menos trades, mais conservador)
IA_MODE = os.getenv("WS_IA_MODE", "learning").strip().lower()  # PADRÃO: learning

# ===================== FILTROS DE QUALIDADE EXTRA =====================
# REQUIRE_TRENDLINE: valor inicial (será ajustado pelo backtest automaticamente)
# No modo LEARNING, começa desativado para permitir mais trades
_trendline_default = "0" if IA_MODE == "learning" else "1"
REQUIRE_TRENDLINE = (os.getenv("WS_REQUIRE_TRENDLINE", _trendline_default).strip() == "1")
# USE_TRENDLINE_FILTER: variável dinâmica que será ajustada pelo backtest
USE_TRENDLINE_FILTER = REQUIRE_TRENDLINE  # Começa com o valor de REQUIRE_TRENDLINE
# MIN_ENTRY_EFF: eficiência mínima para aceitar um sinal
MIN_ENTRY_EFF = float(os.getenv("WS_MIN_ENTRY_EFF", "0.35"))  # Aumentado: 35% de eficiência mínima
# BACKTEST_MIN_WINRATE: taxa mínima do backtest para operar (evita mercado ruim)
BACKTEST_MIN_WINRATE = float(os.getenv("WS_BACKTEST_MIN_WINRATE", "0.42"))  # 42% mínimo para operar (precisa ter alguma edge)

# ===================== AUTO-AJUSTE DE FILTROS =====================
# Contadores para auto-ajuste quando muitos skips consecutivos
MAX_CONSECUTIVE_SKIPS = int(os.getenv("WS_MAX_CONSEC_SKIPS", "5"))  # Após 5 skips, relaxa filtros
AUTO_RELAX_ON_SKIPS = (os.getenv("WS_AUTO_RELAX", "1").strip() == "1")  # Ativar auto-relax

# ===================== IA APRENDE COM BACKTEST (HÍBRIDO COM HISTÓRICO) =====================
# Se ativado, a IA (Bayesian + LightGBM) também aprende com os sinais simulados do backtest
AI_LEARN_FROM_BACKTEST = (os.getenv("WS_AI_LEARN_BACKTEST", "1").strip() == "1")  # ATIVADO: IA aprende com backtest
AI_BACKTEST_WEIGHT = float(os.getenv("WS_AI_BACKTEST_WEIGHT", "0.5"))  # Peso do backtest (0.5 = metade do peso de trades reais)

# HISTÓRICO DE BACKTEST (acumula com decay temporal)
BACKTEST_HISTORY_FILE = os.getenv("WS_BACKTEST_HISTORY_FILE", f"ws_backtest_history_{_broker_suffix}.json")
BACKTEST_HISTORY_MAX_SAMPLES = int(os.getenv("WS_BACKTEST_MAX_SAMPLES", "500"))  # Máximo de amostras no histórico
BACKTEST_HISTORY_DECAY_HOURS = float(os.getenv("WS_BACKTEST_DECAY_HOURS", "6.0"))  # Após 6h, peso começa a decair
BACKTEST_HISTORY_MIN_WEIGHT = float(os.getenv("WS_BACKTEST_MIN_WEIGHT", "0.2"))  # Peso mínimo de amostras antigas (20%)
BACKTEST_USE_ACCUMULATED = (os.getenv("WS_BACKTEST_ACCUMULATE", "1").strip() == "1")  # ATIVADO: usa histórico acumulado

# ===================== PERNADA B (ULTRA RELAXADO - BACKTEST FILTRA) =====================
IMPULSO_MIN_ATR = float(os.getenv("WS_IMPULSO_MIN_ATR", "0.30"))  # ULTRA RELAXADO: 0.30 ATR
IMPULSO_JANELA_MIN = int(os.getenv("WS_IMP_JMIN", "2"))  # mínimo 2 velas
IMPULSO_JANELA_MAX = int(os.getenv("WS_IMP_JMAX", "20"))  # máximo 20 velas

PULLBACK_MIN = int(os.getenv("WS_PB_MIN", "1"))
PULLBACK_MAX = int(os.getenv("WS_PB_MAX", "8"))  # aumentado para 8

RETR_MIN = float(os.getenv("WS_RETR_MIN", "0.05"))  # ULTRA RELAXADO: 5%
RETR_MAX = float(os.getenv("WS_RETR_MAX", "0.95"))  # até 95%

BREAK_MARGIN_ATR = float(os.getenv("WS_BREAK_MARGIN_ATR", "0.01"))  # margem mínima
MAX_BREAK_DISTANCE_ATR = float(os.getenv("WS_MAX_BREAK_DIST_ATR", "0.40"))  # distância maior

# ===================== ANTI-LATERAL (ULTRA RELAXADO) =====================
MIN_EFF_A = float(os.getenv("WS_MIN_EFF_A", "0.25"))  # ULTRA RELAXADO: 25% eficiência

CHOP_LOOKBACK = int(os.getenv("WS_CHOP_LB", "28"))
MAX_COLOR_FLIPS_FRAC = float(os.getenv("WS_MAX_FLIPS", "0.80"))  # permite mais choppiness
MIN_NET_GROSS_EFF = float(os.getenv("WS_MIN_NETGROSS", "0.10"))  # muito relaxado

COMP_LOOKBACK = int(os.getenv("WS_COMP_LB", "18"))
MIN_RANGE_ATR = float(os.getenv("WS_MIN_RANGE_ATR", "0.50"))  # MUITO RELAXADO: 0.50 ATR

LATE_LOOKBACK = int(os.getenv("WS_LATE_LB", "18"))
MAX_LATE_EXT_ATR = float(os.getenv("WS_MAX_LATE_EXT_ATR", "12.0"))  # permite extensão maior

# ===================== QUALIDADE DO GATILHO (RELAXADO) =====================
MIN_BODY_FRAC_BREAK = float(os.getenv("WS_MIN_BODY_FRAC", "0.10"))  # apenas 10% de corpo
MAX_WICK_AGAINST = float(os.getenv("WS_MAX_WICK_AGAINST", "0.75"))  # permite mais pavio

# ===================== SCORE (DEPENDE DO IA_MODE) =====================
# No modo "learning": filtros MUITO relaxados - backtest ajusta depois
# No modo "strict": filtros rigorosos + IA
if IA_MODE == "learning":
    GATE_MIN_SCORE = float(os.getenv("WS_GATE_MIN", "0.48"))   # Score mínimo MUITO RELAXADO - IA aprende entrando
    GATE_SOFT_SCORE = float(os.getenv("WS_GATE_SOFT", "0.40")) # Soft skip muito relaxado
    GATE_CONTEXT_BAD_BLOCK = False  # Não bloqueia por contexto, mas penaliza no score
    GATE_CONTEXT_VERY_BAD = 0.30  # Contexto MUITO relaxado (IA decide, não o filtro)
else:  # strict
    GATE_MIN_SCORE = float(os.getenv("WS_GATE_MIN", "0.75"))   # Score mínimo rigoroso
    GATE_SOFT_SCORE = float(os.getenv("WS_GATE_SOFT", "0.65")) # Soft skip rigoroso
    GATE_CONTEXT_BAD_BLOCK = True  # Bloquear se contexto for ruim
    GATE_CONTEXT_VERY_BAD = 0.50  # Limiar de contexto mais rigoroso

# ===================== ANTI-SPIKE =====================
SPIKE_RANGE_ATR = float(os.getenv("WS_SPIKE_RANGE_ATR", "1.35"))
SPIKE_WICK_FRAC = float(os.getenv("WS_SPIKE_WICK_FRAC", "0.62"))
SPIKE_COOLDOWN_MIN = int(os.getenv("WS_SPIKE_COOLDOWN_MIN", "6"))

# ===================== FILTRO S/R FORTE (AJUSTADO) =====================
SR_LOOKBACK = int(os.getenv("WS_SR_LOOKBACK", "220"))
SR_CLUSTER_ATR = float(os.getenv("WS_SR_CLUSTER_ATR", "0.45"))
SR_MIN_TOUCHES_STRONG = int(os.getenv("WS_SR_MIN_TOUCHES", "3"))

SR_TOP_LEVELS = int(os.getenv("WS_SR_TOP_LEVELS", "6"))
SR_CHECK_NEAR = int(os.getenv("WS_SR_CHECK_NEAR", "2"))
SR_BLOCK_DIST_ATR = float(os.getenv("WS_SR_BLOCK_ATR", "0.65"))  # reduzido de 0.95 para 0.65 (menos bloqueio)

# ===================== LOG =====================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [WS_AUTO_AI] %(message)s"
)
log = logging.getLogger("WS_AUTO_AI")

class C:
    G = "\033[92m"
    R = "\033[91m"
    Y = "\033[93m"
    B = "\033[94m"
    Z = "\033[0m"

def paint(s: str, color: str) -> str:
    return f"{color}{s}{C.Z}"

def dir_color(direction: str) -> str:
    return C.G if direction == "CALL" else (C.R if direction == "PUT" else C.Y)

_cache_ativos: List[str] = []
_cache_ativos_ts: float = 0.0

cooldown: Dict[str, float] = {}
cooldown_spike: Dict[str, float] = {}
cooldown_loss: Dict[str, float] = {}  # Cooldown após LOSS em ativo específico
consecutive_losses: Dict[str, int] = {}  # Contador de losses consecutivos por ativo
global_consecutive_losses: int = 0  # Losses consecutivos globais

# ===================== FILTROS POR ATIVO =====================
# Cada ativo tem seus próprios filtros calibrados pelo backtest
filtros_por_ativo: Dict[str, Dict[str, Any]] = {}
# Estrutura: {
#   "EURUSD-OTC": {"min_ctx": 0.40, "min_score": 0.55, "taxa": 0.65, "sinais": 8, "habilitado": True},
#   ...
# }

# Ativos que já foram analisados no backtest (para detectar mudanças)
ativos_analisados_backtest: List[str] = []

# LightGBM globals
lgbm_model: Any = None  # Modelo LightGBM treinado
lgbm_data: List[Dict] = []  # Dados de treino acumulados
lgbm_trade_count: int = 0  # Contador para retreino
lgbm_reliable: bool = False  # Se True, modelo LGBM tem validação >= 55% (confiável)
lgbm_val_accuracy: float = 0.0  # Última accuracy de validação medida

# ===================== TEMPO (candle fechado) =====================
def seconds_to_next(tf: int) -> float:
    now = time.time()
    return tf - (now % tf)

def wait_until_minus(tf: int, seconds_before: int):
    while True:
        s = seconds_to_next(tf)
        if s <= seconds_before:
            return
        time.sleep(min(0.25, max(0.04, s - seconds_before)))

def wait_for_next_open(tf: int):
    s = seconds_to_next(tf)
    time.sleep(s + 0.12)

def end_ts_closed(tf: int) -> float:
    now = time.time()
    return now - (now % tf) - 1  # garante candle fechado

# ===================== PATCH WEBSOCKET =====================
def patch_websocket_on_close():
    try:
        if BROKER_TYPE == "bullex":
            from bullexapi.ws.client import WebsocketClient
        elif BROKER_TYPE == "casatrader":
            from casatraderapi.ws.client import WebsocketClient
        else:
            from iqoptionapi.ws.client import WebsocketClient
        if getattr(WebsocketClient, "__WS_PATCHED__", False):
            return
        old = WebsocketClient.on_close

        def on_close_compat(self, *args, **kwargs):
            try:
                return old(self)
            except TypeError:
                try:
                    return old(self, *args, **kwargs)
                except Exception:
                    return None
            except Exception:
                return None

        WebsocketClient.on_close = on_close_compat
        WebsocketClient.__WS_PATCHED__ = True
        log.info("Patch aplicado: WebsocketClient.on_close compatível.")
    except Exception as e:
        log.warning(f"Patch websocket falhou: {e}")

# ===================== CONEXÃO COM CORRETORA =====================
def conectar_iq(max_retries: int = 5) -> BrokerAPI:
    if not EMAIL or not SENHA:
        raise RuntimeError(f"Defina credenciais para {_BROKER_NAME} nas variáveis de ambiente.")
    patch_websocket_on_close()
    
    for attempt in range(1, max_retries + 1):
        try:
            log.info(f"Conectando à {_BROKER_NAME}... (tentativa {attempt}/{max_retries})")
            iq = BrokerAPI(EMAIL, SENHA)
            iq.connect()

            for _ in range(15):
                if iq.check_connect():
                    break
                time.sleep(1.5)

            if not iq.check_connect():
                raise ConnectionError("check_connect() retornou False")

            iq.change_balance(CONTA)
            try:
                log.info(f"Conectado | Saldo: {iq.get_balance():.2f} | Conta: {CONTA}")
            except Exception:
                log.info(f"Conectado | Conta: {CONTA}")

            return iq
        except Exception as e:
            log.warning(paint(f"Tentativa {attempt}/{max_retries} falhou: {e}", C.Y))
            if attempt < max_retries:
                wait_time = min(10 * attempt, 30)  # 10s, 20s, 30s, 30s...
                log.info(paint(f"Aguardando {wait_time}s antes de tentar novamente...", C.Y))
                time.sleep(wait_time)
            else:
                raise RuntimeError(f"Falha na conexão após {max_retries} tentativas: {e}")

def ensure_connected(iq: Optional[BrokerAPI]) -> BrokerAPI:
    if iq is None:
        return conectar_iq()
    try:
        if iq.check_connect():
            return iq
    except Exception:
        pass

    log.warning(paint("Conexão caiu. Tentando reconectar...", C.Y))
    try:
        iq.connect()
        for _ in range(15):
            if iq.check_connect():
                iq.change_balance(CONTA)
                log.info("Reconectado.")
                return iq
            time.sleep(1.5)
    except Exception:
        pass

    return conectar_iq()

def safe_call(iq: BrokerAPI, fn, *args, **kwargs):
    try:
        return fn(*args, **kwargs)
    except Exception as e:
        msg = str(e).lower()
        if ("10054" in msg) or ("cancelamento" in msg) or ("goodbye" in msg) or ("10053" in msg):
            log.error(paint(f"Erro de conexao: {e}", C.R))
            ensure_connected(iq)
            return fn(*args, **kwargs)
        raise

# ===================== CANDLES =====================
def get_candles_df(iq: BrokerAPI, ativo: str, timeframe: int, n: int, end_ts: Optional[float] = None, min_candles: int = 0) -> Optional[pd.DataFrame]:
    try:
        if end_ts is None:
            end_ts = time.time()

        candles = safe_call(iq, iq.get_candles, ativo, timeframe, n, end_ts)
        if not candles or isinstance(candles, int):
            return None

        df = pd.DataFrame(candles)
        if "from" in df.columns and "time" not in df.columns:
            df.rename(columns={"from": "time"}, inplace=True)
        if "min" in df.columns:
            df.rename(columns={"min": "low"}, inplace=True)
        if "max" in df.columns:
            df.rename(columns={"max": "high"}, inplace=True)

        if "time" not in df.columns:
            return None

        df["time"] = pd.to_datetime(df["time"], unit="s")
        df.set_index("time", inplace=True)

        needed = ["open", "high", "low", "close"]
        for col in needed:
            if col not in df.columns:
                return None

        df = df[needed].dropna().sort_index()

        # precisa ser grande o bastante pro SR + filtros
        need_min = min_candles if min_candles > 0 else max(220, SR_LOOKBACK + 20)
        if len(df) < need_min:
            return None
        return df
    except Exception:
        return None

# ===================== ATIVOS / PAYOUT =====================
def obter_top_ativos_otc(iq: BrokerAPI) -> List[str]:
    global _cache_ativos, _cache_ativos_ts
    now = time.time()
    if _cache_ativos and (now - _cache_ativos_ts) < PAYOUT_REFRESH_SEC:
        return _cache_ativos

    try:
        dados = safe_call(iq, iq.get_all_open_time)
        turbo = dados.get("turbo", {})
    except Exception:
        return []

    abertos = [a for a, info in turbo.items() if info.get("open", False)]
    abertos_otc = [a for a in abertos if "-OTC" in a.upper()]
    if not abertos_otc:
        abertos_otc = abertos

    filtrados = []
    for a in abertos_otc:
        try:
            payout = safe_call(iq, iq.get_digital_payout, a)
            payout = int(payout) if payout is not None else 0
        except Exception:
            payout = 0
        if payout >= PAYOUT_MINIMO:
            filtrados.append((a, payout))

    filtrados.sort(key=lambda x: x[1], reverse=True)
    top = [a for a, _ in filtrados[:NUM_ATIVOS]]
    _cache_ativos = top
    _cache_ativos_ts = now
    log.info(f"TOP ativos: {top}")
    return top

# ===================== HELPERS =====================
def atr(df: pd.DataFrame, period: int = 14) -> float:
    sub = df.tail(period + 2)
    h = sub["high"].to_numpy(float)
    l = sub["low"].to_numpy(float)
    c = sub["close"].to_numpy(float)
    tr = np.maximum(
        h[1:] - l[1:],
        np.maximum(np.abs(h[1:] - c[:-1]), np.abs(l[1:] - c[:-1]))
    )
    return float(np.mean(tr[-period:]))

# ===================== LINHA DE TENDÊNCIA (LTA/LTB) =====================
def detect_trendline(df: pd.DataFrame, lookback: int, direction: str) -> Optional[Tuple[float, float]]:
    """
    Detecta linha de tendência (LTA para alta, LTB para baixa).
    Retorna (slope, intercept) ou None se não encontrar.
    """
    if len(df) < lookback:
        return None

    sub = df.tail(lookback)

    if direction == "CALL":
        # LTA - conecta mínimas ascendentes (suporte)
        pivots = []
        lows = sub["low"].to_numpy(float)

        # Encontra pivôs de baixa (mínimas locais)
        for i in range(2, len(lows) - 2):
            if lows[i] < lows[i-1] and lows[i] < lows[i-2] and \
               lows[i] < lows[i+1] and lows[i] < lows[i+2]:
                pivots.append((i, lows[i]))

        # Precisa de pelo menos 2 pivôs ascendentes
        if len(pivots) < 2:
            return None

        # Verifica se há tendência ascendente nos pivôs
        if pivots[-1][1] <= pivots[0][1]:
            return None

        # Calcula linha de tendência
        x = np.array([p[0] for p in pivots])
        y = np.array([p[1] for p in pivots])
        slope, intercept = np.polyfit(x, y, 1)

        # Só aceita se slope positivo (ascendente)
        if slope <= 0:
            return None

        return (float(slope), float(intercept))

    else:  # PUT
        # LTB - conecta máximas descendentes (resistência)
        pivots = []
        highs = sub["high"].to_numpy(float)

        # Encontra pivôs de alta (máximas locais)
        for i in range(2, len(highs) - 2):
            if highs[i] > highs[i-1] and highs[i] > highs[i-2] and \
               highs[i] > highs[i+1] and highs[i] > highs[i+2]:
                pivots.append((i, highs[i]))

        # Precisa de pelo menos 2 pivôs descendentes
        if len(pivots) < 2:
            return None

        # Verifica se há tendência descendente nos pivôs
        if pivots[-1][1] >= pivots[0][1]:
            return None

        # Calcula linha de tendência
        x = np.array([p[0] for p in pivots])
        y = np.array([p[1] for p in pivots])
        slope, intercept = np.polyfit(x, y, 1)

        # Só aceita se slope negativo (descendente)
        if slope >= 0:
            return None

        return (float(slope), float(intercept))

def check_trendline_confluence(df: pd.DataFrame, pb_high: float, pb_low: float,
                                direction: str, atr_val: float) -> Dict[str, Any]:
    """
    Verifica se o pullback tocou/respeitou a linha de tendência.
    Retorna score de confluência com a LT.
    """
    # Tenta detectar linha de tendência nas últimas 30-50 velas
    trendline = detect_trendline(df.tail(50), 50, direction)

    if trendline is None:
        return {"has_trendline": False, "confluence": 0.0, "distance": 999.0}

    slope, intercept = trendline

    # Calcula valor da LT na posição do pullback (última vela)
    x_pb = len(df.tail(50)) - 1  # posição do pullback
    lt_value = slope * x_pb + intercept

    if direction == "CALL":
        # Para CALL, pullback deve tocar a LTA (suporte)
        # Verifica se a mínima do pullback está próxima da LTA
        distance = abs(pb_low - lt_value) / max(atr_val, 1e-9)

        # Se tocou a LTA (distância < 0.3 ATR), excelente confluência
        if distance < 0.3:
            return {"has_trendline": True, "confluence": 1.0, "distance": distance, "lt_value": lt_value}
        # Próximo mas não tocou
        elif distance < 0.6:
            return {"has_trendline": True, "confluence": 0.6, "distance": distance, "lt_value": lt_value}
        # Muito longe da LTA
        else:
            return {"has_trendline": True, "confluence": 0.2, "distance": distance, "lt_value": lt_value}

    else:  # PUT
        # Para PUT, pullback deve tocar a LTB (resistência)
        # Verifica se a máxima do pullback está próxima da LTB
        distance = abs(pb_high - lt_value) / max(atr_val, 1e-9)

        # Se tocou a LTB
        if distance < 0.3:
            return {"has_trendline": True, "confluence": 1.0, "distance": distance, "lt_value": lt_value}
        elif distance < 0.6:
            return {"has_trendline": True, "confluence": 0.6, "distance": distance, "lt_value": lt_value}
        else:
            return {"has_trendline": True, "confluence": 0.2, "distance": distance, "lt_value": lt_value}

def candle_dir(row: pd.Series) -> int:
    o = float(row["open"]); c = float(row["close"])
    return 1 if c > o else (-1 if c < o else 0)

def candle_range(row: pd.Series) -> float:
    return float(row["high"]) - float(row["low"])

def wick_fractions(row: pd.Series) -> Dict[str, float]:
    o = float(row["open"]); c = float(row["close"])
    h = float(row["high"]); l = float(row["low"])
    rng = max(h - l, 1e-9)
    upper = h - max(o, c)
    lower = min(o, c) - l
    body  = abs(c - o)
    return {"rng": rng, "upper_frac": upper / rng, "lower_frac": lower / rng, "body_frac": body / rng}

def is_spike_wicky(row: pd.Series, atr_val: float) -> bool:
    w = wick_fractions(row)
    if candle_range(row) < SPIKE_RANGE_ATR * atr_val:
        return False
    return (w["upper_frac"] >= SPIKE_WICK_FRAC) or (w["lower_frac"] >= SPIKE_WICK_FRAC)

def leg_efficiency(df_leg: pd.DataFrame) -> float:
    if len(df_leg) < 3:
        return 0.0
    closes = df_leg["close"].to_numpy(float)
    net = abs(closes[-1] - closes[0])
    gross = np.sum(np.abs(np.diff(closes))) + 1e-9
    return float(net / gross)

def chop_stats(df_m1: pd.DataFrame, lookback: int) -> Tuple[float, float]:
    sub = df_m1.tail(lookback)
    if len(sub) < 6:
        return 1.0, 0.0
    dirs = [candle_dir(sub.iloc[i]) for i in range(len(sub))]
    dirs2 = [d for d in dirs if d != 0]
    if len(dirs2) < 6:
        return 1.0, 0.0
    flips = 0
    for i in range(1, len(dirs2)):
        if dirs2[i] != dirs2[i-1]:
            flips += 1
    flips_frac = flips / max(1, (len(dirs2) - 1))
    eff = leg_efficiency(sub)
    return float(flips_frac), float(eff)

def compression_ratio(df_m1: pd.DataFrame, atr_val: float, lookback: int) -> float:
    sub = df_m1.tail(lookback)
    if len(sub) < 6:
        return 0.0
    rng = float(sub["high"].max() - sub["low"].min())
    return float(rng / max(atr_val, 1e-9))

def late_extension_atr(df_m1: pd.DataFrame, atr_val: float, lookback: int) -> float:
    sub = df_m1.tail(lookback)
    if len(sub) < 6:
        return 0.0
    o0 = float(sub["open"].iloc[0])
    cN = float(sub["close"].iloc[-1])
    return float(abs(cN - o0) / max(atr_val, 1e-9))

# ===================== S/R FORTE (múltiplas regiões) =====================
def _cluster_levels(levels: List[float], tol: float) -> List[Tuple[float, int]]:
    if not levels:
        return []
    levels = sorted(levels)
    clusters = []
    cur = [levels[0]]
    for x in levels[1:]:
        if abs(x - cur[-1]) <= tol:
            cur.append(x)
        else:
            clusters.append((float(np.mean(cur)), len(cur)))
            cur = [x]
    clusters.append((float(np.mean(cur)), len(cur)))
    clusters.sort(key=lambda t: t[1], reverse=True)
    return clusters

def strong_sr_levels_last200(df_m1: pd.DataFrame, atr_val: float) -> Tuple[List[Tuple[float,int]], List[Tuple[float,int]]]:
    """
    Retorna (resistencias, suportes) com base nas últimas SR_LOOKBACK velas (>=200).
    """
    sub = df_m1.tail(SR_LOOKBACK)
    h = sub["high"].to_numpy(float)
    l = sub["low"].to_numpy(float)

    highs: List[float] = []
    lows: List[float] = []

    k = 2
    for i in range(k, len(sub) - k):
        if h[i] == np.max(h[i-k:i+k+1]):
            highs.append(float(h[i]))
        if l[i] == np.min(l[i-k:i+k+1]):
            lows.append(float(l[i]))

    tol_price = max(atr_val * SR_CLUSTER_ATR, 1e-9)

    res = _cluster_levels(highs, tol_price)
    sup = _cluster_levels(lows, tol_price)

    res = [(lvl, n) for (lvl, n) in res if n >= SR_MIN_TOUCHES_STRONG]
    sup = [(lvl, n) for (lvl, n) in sup if n >= SR_MIN_TOUCHES_STRONG]
    return res, sup

def pick_top_levels(levels: List[Tuple[float,int]], top_n: int) -> List[Tuple[float,int]]:
    return sorted(levels, key=lambda t: t[1], reverse=True)[:top_n]

def nearest_k(levels: List[Tuple[float,int]], price: float, k: int) -> List[Tuple[float,int,float]]:
    arr = [(lvl, touches, abs(lvl - price)) for (lvl, touches) in levels]
    arr.sort(key=lambda x: x[2])
    return arr[:k]

def sr_block_directional_multi(df_m1: pd.DataFrame, atr_val: float, direction: str) -> Optional[str]:
    """
    Bloqueia CALL perto de resistência forte acima.
    Bloqueia PUT perto de suporte forte abaixo.
    Considera as SR_CHECK_NEAR regiões mais próximas e as SR_TOP_LEVELS mais fortes.
    """
    res, sup = strong_sr_levels_last200(df_m1, atr_val)
    price = float(df_m1["close"].iloc[-1])
    atr_safe = max(atr_val, 1e-9)

    res = pick_top_levels(res, SR_TOP_LEVELS)
    sup = pick_top_levels(sup, SR_TOP_LEVELS)

    if direction == "CALL" and res:
        above = [(lvl,t) for (lvl,t) in res if lvl >= price]
        if not above:
            return None
        cand = nearest_k(above, price, SR_CHECK_NEAR)
        for lvl, touches, dist_abs in cand:
            dist_atr = dist_abs / atr_safe
            zone = min(SR_BLOCK_DIST_ATR + 0.10 * max(0, touches - SR_MIN_TOUCHES_STRONG), 1.30)
            if dist_atr <= zone:
                return f"bloqueado_RES(nivel={lvl:.6f},toques={touches},dist={dist_atr:.2f}ATR<=zona{zone:.2f})"
        return None

    if direction == "PUT" and sup:
        below = [(lvl,t) for (lvl,t) in sup if lvl <= price]
        if not below:
            return None
        cand = nearest_k(below, price, SR_CHECK_NEAR)
        for lvl, touches, dist_abs in cand:
            dist_atr = dist_abs / atr_safe
            zone = min(SR_BLOCK_DIST_ATR + 0.10 * max(0, touches - SR_MIN_TOUCHES_STRONG), 1.30)
            if dist_atr <= zone:
                return f"bloqueado_SUP(nivel={lvl:.6f},toques={touches},dist={dist_atr:.2f}ATR<=zona{zone:.2f})"
        return None

    return None

def sr_pingpong_zone(df_m1: pd.DataFrame, atr_val: float) -> Optional[str]:
    """
    Se tiver suporte e resistência próximos ao preço, vira "corredor" -> evita operar.
    """
    res, sup = strong_sr_levels_last200(df_m1, atr_val)
    if not res or not sup:
        return None
    price = float(df_m1["close"].iloc[-1])
    atr_safe = max(atr_val, 1e-9)

    # pega níveis mais próximos por distância (não por força)
    res_near = sorted([(lvl,t) for (lvl,t) in res], key=lambda x: abs(x[0]-price))[:2]
    sup_near = sorted([(lvl,t) for (lvl,t) in sup], key=lambda x: abs(x[0]-price))[:2]

    # melhor resistência acima e melhor suporte abaixo
    above = [(lvl,t) for (lvl,t) in res_near if lvl >= price]
    below = [(lvl,t) for (lvl,t) in sup_near if lvl <= price]
    if not above or not below:
        return None

    r_lvl, r_t = min(above, key=lambda x: abs(x[0]-price))
    s_lvl, s_t = min(below, key=lambda x: abs(x[0]-price))

    corridor_atr = abs(r_lvl - s_lvl) / atr_safe
    # corredor curto => mercado batendo em paredes (reduzido de 1.60 para 0.85 para bloquear menos)
    if corridor_atr <= 0.85:
        return f"pingpong(corredor={corridor_atr:.2f}ATR sup={s_lvl:.6f} res={r_lvl:.6f})"
    return None

# ===================== S/R PROXIMITY SCORE (SINAL POSITIVO - estilo Candle Mind) =====================
def sr_proximity_score(df_m1: pd.DataFrame, atr_val: float, direction: str,
                       pb_high: float, pb_low: float) -> Dict[str, Any]:
    """
    Detecta quando o pullback RETORNA a uma zona de S/R forte.
    CALL: pullback low perto de suporte = preço testou zona de suporte = sinal de compra
    PUT:  pullback high perto de resistência = preço testou zona de resistência = sinal de venda
    Similar ao que o Candle Mind faz: identifica S/R e quando preço volta à região,
    mostra alta probabilidade de entrada.
    """
    res, sup = strong_sr_levels_last200(df_m1, atr_val)
    atr_safe = max(atr_val, 1e-9)

    result: Dict[str, Any] = {
        "sr_proximity": 0.0,
        "sr_bonus": 0.0,
        "sr_touches": 0,
        "sr_level": 0.0,
        "sr_reason": "sem_sr"
    }

    if direction == "CALL" and sup:
        # CALL: pullback low perto de SUPORTE = preço voltou para zona de suporte
        ref_price = pb_low
        candidates = nearest_k(sup, ref_price, 3)

        for lvl, touches, dist_abs in candidates:
            dist_atr = dist_abs / atr_safe

            if dist_atr <= 0.80:
                proximity = max(0.0, 1.0 - (dist_atr / 0.80))

                # Bonus escalonado: quanto mais perto + mais toques = maior bonus
                if dist_atr <= 0.25 and touches >= 4:
                    bonus = 0.25   # pullback bateu exatamente no suporte forte
                elif dist_atr <= 0.40 and touches >= 3:
                    bonus = 0.18
                elif dist_atr <= 0.60 and touches >= 3:
                    bonus = 0.12
                elif dist_atr <= 0.80:
                    bonus = 0.05
                else:
                    bonus = 0.0

                if proximity > result["sr_proximity"]:
                    result = {
                        "sr_proximity": float(proximity),
                        "sr_bonus": float(bonus),
                        "sr_touches": int(touches),
                        "sr_level": float(lvl),
                        "sr_reason": f"SUP(lvl={lvl:.6f},tq={touches},dist={dist_atr:.2f}ATR,prox={proximity:.2f})"
                    }

    elif direction == "PUT" and res:
        # PUT: pullback high perto de RESISTÊNCIA = preço voltou para zona de resistência
        ref_price = pb_high
        candidates = nearest_k(res, ref_price, 3)

        for lvl, touches, dist_abs in candidates:
            dist_atr = dist_abs / atr_safe

            if dist_atr <= 0.80:
                proximity = max(0.0, 1.0 - (dist_atr / 0.80))

                if dist_atr <= 0.25 and touches >= 4:
                    bonus = 0.25
                elif dist_atr <= 0.40 and touches >= 3:
                    bonus = 0.18
                elif dist_atr <= 0.60 and touches >= 3:
                    bonus = 0.12
                elif dist_atr <= 0.80:
                    bonus = 0.05
                else:
                    bonus = 0.0

                if proximity > result["sr_proximity"]:
                    result = {
                        "sr_proximity": float(proximity),
                        "sr_bonus": float(bonus),
                        "sr_touches": int(touches),
                        "sr_level": float(lvl),
                        "sr_reason": f"RES(lvl={lvl:.6f},tq={touches},dist={dist_atr:.2f}ATR,prox={proximity:.2f})"
                    }

    return result

# ===================== PROJEÇÃO E VALIDAÇÃO DE ENTRADA =====================
def validate_entry_quality(df_m1: pd.DataFrame, atr_val: float, direction: str, entry_price: float, pb_high: float, pb_low: float) -> Dict[str, Any]:
    """
    Valida a qualidade da entrada projetando alvos e analisando risco/retorno.
    Retorna score de confiança e razão de risco/retorno.
    """
    if len(df_m1) < 5:
        return {"valid": False, "confidence": 0.0, "reason": "dados_insuficientes"}

    # 1. ANÁLISE DO CANDLE DE ENTRADA
    last_candle = df_m1.iloc[-1]
    open_price = float(last_candle["open"])
    close_price = float(last_candle["close"])
    high_price = float(last_candle["high"])
    low_price = float(last_candle["low"])

    candle_range = high_price - low_price
    body = abs(close_price - open_price)
    body_ratio = body / max(candle_range, 1e-9)

    # Candle de entrada deve ter corpo razoável (mais relaxado no modo learning)
    min_body = 0.25 if IA_MODE != "learning" else 0.10
    if body_ratio < min_body:
        return {"valid": False, "confidence": 0.0, "reason": f"candle_fraco(body={body_ratio:.2f})"}

    # 2. PROJEÇÃO DE ALVO E STOP
    if direction == "CALL":
        # Stop abaixo da mínima do pullback
        stop_loss = pb_low - (0.15 * atr_val)
        risk = entry_price - stop_loss

        # Alvo: projeta 1.5x o risco (R:R 1:1.5)
        target_1 = entry_price + (risk * 1.5)

        # Verifica se há espaço para o alvo (sem resistência próxima)
        recent_highs = df_m1.tail(20)["high"].to_numpy(float)
        max_recent = float(np.max(recent_highs))

        # Se alvo muito próximo de máximas recentes, pode ser arriscado
        if target_1 > max_recent * 1.005:  # alvo acima das máximas
            confidence = 0.75
        else:
            confidence = 0.55

    else:  # PUT
        # Stop acima da máxima do pullback
        stop_loss = pb_high + (0.15 * atr_val)
        risk = stop_loss - entry_price

        # Alvo: projeta 1.5x o risco (R:R 1:1.5)
        target_1 = entry_price - (risk * 1.5)

        # Verifica espaço para o alvo
        recent_lows = df_m1.tail(20)["low"].to_numpy(float)
        min_recent = float(np.min(recent_lows))

        if target_1 < min_recent * 0.995:  # alvo abaixo das mínimas
            confidence = 0.75
        else:
            confidence = 0.55

    # 3. RAZÃO RISCO/RETORNO
    risk_atr = risk / max(atr_val, 1e-9)

    # Risco muito grande ou muito pequeno é ruim (mais relaxado no modo learning)
    min_risk = 0.2 if IA_MODE != "learning" else 0.05
    max_risk = 2.0 if IA_MODE != "learning" else 4.0
    if risk_atr < min_risk or risk_atr > max_risk:
        return {"valid": False, "confidence": 0.0, "reason": f"risco_inadequado({risk_atr:.2f}ATR)"}

    # 4. MOMENTUM DO BREAKOUT
    last_3_closes = df_m1.tail(3)["close"].to_numpy(float)
    momentum = abs(last_3_closes[-1] - last_3_closes[0]) / max(atr_val, 1e-9)

    # Momentum fraco = breakout fraco (reduzido de 0.15 para 0.10)
    if momentum < 0.10:
        confidence *= 0.80  # penaliza menos

    # 5. ALINHAMENTO DE VELAS
    last_3 = df_m1.tail(3)
    aligned = 0
    for _, row in last_3.iterrows():
        c = float(row["close"])
        o = float(row["open"])
        if (direction == "CALL" and c > o) or (direction == "PUT" and c < o):
            aligned += 1

    alignment_ratio = aligned / 3.0
    if alignment_ratio >= 0.67:  # 2 de 3 velas alinhadas
        confidence *= 1.15  # bônus
    elif alignment_ratio < 0.34:
        confidence *= 0.80  # penaliza

    # Confidence final
    confidence = min(1.0, max(0.0, confidence))

    # Score mínimo para aprovar (reduzido de 0.50 para 0.40)
    if confidence < 0.40:
        return {"valid": False, "confidence": confidence, "reason": f"confianca_baixa({confidence:.2f})"}

    return {
        "valid": True,
        "confidence": float(confidence),
        "risk_atr": float(risk_atr),
        "risk_reward": 1.5,
        "momentum": float(momentum),
        "body_ratio": float(body_ratio),
        "alignment": float(alignment_ratio),
        "reason": "entrada_validada"
    }

# ===================== VALIDAÇÃO DE CONTINUAÇÃO DE TENDÊNCIA =====================
def validate_trend_continuation(df_m1: pd.DataFrame, impulso_dir: str, pb_end_idx: int) -> Dict[str, Any]:
    """
    Valida se a entrada está em continuação de tendência.
    SUAVIZADO: Não bloqueia totalmente, apenas reduz score se contra tendência forte.
    """
    if len(df_m1) < pb_end_idx + 30:
        return {"valid": True, "reason": "dados_insuficientes", "strength": 0.5}

    # Pega as 15-25 velas ANTES da pernada A começar
    pre_impulse = df_m1.iloc[max(0, pb_end_idx - 25):pb_end_idx - 5]

    if len(pre_impulse) < 10:
        return {"valid": True, "reason": "contexto_curto", "strength": 0.5}

    closes = pre_impulse["close"].to_numpy(float)

    # Análise de tendência predominante
    price_change = closes[-1] - closes[0]
    price_change_pct = abs(price_change) / max(closes[0], 1e-9)

    if impulso_dir == "PUT":
        # Para PUT, queremos tendência de queda ANTES do impulso A
        if price_change > 0:
            # Preço estava subindo antes - só bloqueia se for tendência FORTE
            if price_change_pct > 0.015:  # Subida maior que 1.5%
                return {"valid": False, "reason": "contra_tendencia_forte_alta", "strength": 0.2}
            # Subida fraca, permite mas com score reduzido
            return {"valid": True, "reason": "contra_tendencia_fraca", "strength": 0.4}
        # Confirma tendência de queda
        return {"valid": True, "reason": "continuacao_queda", "strength": min(1.0, price_change_pct * 50)}

    else:  # CALL
        # Para CALL, queremos tendência de alta ANTES do impulso A
        if price_change < 0:
            # Preço estava caindo antes - só bloqueia se for tendência FORTE
            if price_change_pct > 0.015:  # Queda maior que 1.5%
                return {"valid": False, "reason": "contra_tendencia_forte_baixa", "strength": 0.2}
            # Queda fraca, permite mas com score reduzido
            return {"valid": True, "reason": "contra_tendencia_fraca", "strength": 0.4}
        # Confirma tendência de alta
        return {"valid": True, "reason": "continuacao_alta", "strength": min(1.0, price_change_pct * 50)}

# ===================== ANÁLISE INTELIGENTE DE CONTEXTO (SEM INDICADORES TRADICIONAIS) =====================
def analyze_market_context(df_m1: pd.DataFrame, atr_val: float) -> Dict[str, Any]:
    """
    Análise contextual inteligente do mercado sem depender de indicadores tradicionais.
    Foca em padrões de price action puros e estrutura de mercado.
    """
    if len(df_m1) < 50:
        return {"quality": 0.0, "context": "insuficiente"}

    # 1. MOMENTUM DIRECIONAL (últimas 20 velas)
    recent = df_m1.tail(20)
    closes = recent["close"].to_numpy(float)
    highs = recent["high"].to_numpy(float)
    lows = recent["low"].to_numpy(float)

    # Conta velas na direção vs contra direção
    bullish = sum(1 for i in range(len(recent)) if closes[i] > recent["open"].iloc[i])
    bearish = sum(1 for i in range(len(recent)) if closes[i] < recent["open"].iloc[i])
    directional_bias = abs(bullish - bearish) / len(recent)  # 0-1, quanto maior mais direcional

    # 2. VOLATILIDADE ORDENADA (mercado respeitando movimentos)
    ranges = [highs[i] - lows[i] for i in range(len(recent))]
    avg_range = np.mean(ranges)
    std_range = np.std(ranges)
    volatility_consistency = 1.0 - min(1.0, std_range / max(avg_range, 1e-9))

    # 3. HIGHER HIGHS / LOWER LOWS (estrutura de tendência)
    hh_count = sum(1 for i in range(5, len(recent)) if highs[i] > max(highs[i-5:i]))
    ll_count = sum(1 for i in range(5, len(recent)) if lows[i] < min(lows[i-5:i]))
    structure_quality = max(hh_count, ll_count) / max(1, len(recent) - 5)

    # 4. MOMENTUM DE PREÇO (velocidade da última perna)
    last_10 = closes[-10:]
    price_momentum = abs(last_10[-1] - last_10[0]) / (max(atr_val, 1e-9) * 10)
    price_momentum = min(1.0, price_momentum)  # normaliza

    # 5. LIMPEZA DOS CANDLES (menos wicks, mais body)
    body_ratios = []
    for i in range(len(recent)):
        o = recent["open"].iloc[i]
        c = recent["close"].iloc[i]
        h = recent["high"].iloc[i]
        l = recent["low"].iloc[i]
        body = abs(c - o)
        total = h - l
        if total > 1e-9:
            body_ratios.append(body / total)
    avg_body_ratio = np.mean(body_ratios) if body_ratios else 0.0

    # SCORE FINAL DE QUALIDADE (0-1)
    quality = (
        directional_bias * 0.25 +
        volatility_consistency * 0.20 +
        structure_quality * 0.25 +
        price_momentum * 0.15 +
        avg_body_ratio * 0.15
    )

    return {
        "quality": float(quality),
        "directional_bias": float(directional_bias),
        "volatility_consistency": float(volatility_consistency),
        "structure_quality": float(structure_quality),
        "price_momentum": float(price_momentum),
        "body_ratio": float(avg_body_ratio),
        "context": "excelente" if quality > 0.70 else ("bom" if quality > 0.55 else ("mediano" if quality > 0.40 else "ruim"))
    }

# ===================== GESTÃO DE BANCA =====================
def calcular_stake_dinamico(iq: BrokerAPI, base_stake: float) -> float:
    """
    Calcula stake dinâmico baseado em % da banca atual.
    Se USE_DYNAMIC_STAKE=True, usa PERCENT_BANCA% do saldo.
    """
    if not USE_DYNAMIC_STAKE:
        return float(max(VALOR_MINIMO, base_stake))

    try:
        saldo = float(iq.get_balance())
        stake = (saldo * PERCENT_BANCA) / 100.0
        return float(max(VALOR_MINIMO, stake))
    except Exception:
        return float(max(VALOR_MINIMO, base_stake))

def verificar_meta_atingida(saldo_inicial: float, saldo_atual: float) -> Tuple[bool, float]:
    """
    Verifica se atingiu a meta de lucro ou stop loss.
    Retorna (deve_parar, lucro_percent).
    """
    lucro = saldo_atual - saldo_inicial
    lucro_percent = (lucro / saldo_inicial) * 100.0

    if lucro_percent >= META_LUCRO_PERCENT:
        return True, lucro_percent

    if lucro_percent <= -STOP_LOSS_PERCENT:
        return True, lucro_percent

    return False, lucro_percent

# ===================== IA ONLINE (Bayes + UCB) =====================
def _safe_load_json(path: str) -> Dict[str, Any]:
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {"meta": {"total": 0}, "arms": {}}

def _safe_save_json(path: str, data: Dict[str, Any]):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

# ===================== LIGHTGBM - GRADIENT BOOSTING =====================

def lgbm_extract_features(setup: Dict[str, Any], df_m1: Optional[pd.DataFrame] = None) -> np.ndarray:
    """
    Extrai features numéricas do setup para o LightGBM.
    Features:
    - score, retr, A_atr, effA, flips, pb_len, distBreak
    - market_quality, late_ext, compression
    - dir_encoded (CALL=1, PUT=-1)
    """
    # Features básicas do setup
    score = float(setup.get("score", 0.0))
    retr = float(setup.get("retr", 0.0))
    A_atr = float(setup.get("A_atr", 0.0))
    effA = float(setup.get("effA", 0.0))
    flips = float(setup.get("flips", 0.0))
    pb_len = float(setup.get("pb_len", 0))
    distBreak = float(setup.get("distBreak", 0.0))
    late_ext = float(setup.get("late_ext", 0.0))
    compression = float(setup.get("compression", 0.0))
    market_quality = float(setup.get("market_quality", 0.5))
    entry_conf = float(setup.get("entry_confidence", 0.5))
    
    # Contexto do setup
    ctx = str(setup.get("ctx", "neutro"))
    ctx_score = 1.0 if ctx == "bom" else (0.5 if ctx == "neutro" else 0.0)
    
    # Direção encodada
    dir_str = str(setup.get("dir", "NEUTRAL"))
    dir_enc = 1.0 if dir_str == "CALL" else (-1.0 if dir_str == "PUT" else 0.0)
    
    features = np.array([
        score, retr, A_atr, effA, flips, pb_len, distBreak,
        late_ext, compression, market_quality, entry_conf, ctx_score, dir_enc
    ], dtype=np.float32)
    
    return features

def lgbm_load_model():
    """Carrega modelo LightGBM do disco se existir."""
    global lgbm_model
    if not LGBM_ON or lgbm_model is not None:
        return
    
    try:
        if os.path.exists(LGBM_MODEL_FILE):
            with open(LGBM_MODEL_FILE, "rb") as f:
                lgbm_model = pickle.load(f)
            log.info(f"[LGBM] Modelo carregado de {LGBM_MODEL_FILE}")
    except Exception as e:
        log.warning(f"[LGBM] Erro ao carregar modelo: {e}")
        lgbm_model = None

def lgbm_save_model():
    """Salva modelo LightGBM no disco."""
    global lgbm_model
    if lgbm_model is None:
        return
    
    try:
        with open(LGBM_MODEL_FILE, "wb") as f:
            pickle.dump(lgbm_model, f)
        log.info(f"[LGBM] Modelo salvo em {LGBM_MODEL_FILE}")
    except Exception as e:
        log.warning(f"[LGBM] Erro ao salvar modelo: {e}")

def lgbm_load_data():
    """Carrega dados de treino do disco."""
    global lgbm_data
    try:
        if os.path.exists(LGBM_DATA_FILE):
            with open(LGBM_DATA_FILE, "r", encoding="utf-8") as f:
                lgbm_data = json.load(f)
            log.info(f"[LGBM] {len(lgbm_data)} amostras carregadas")
    except Exception:
        lgbm_data = []

def lgbm_save_data():
    """Salva dados de treino no disco."""
    global lgbm_data
    try:
        with open(LGBM_DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(lgbm_data, f, ensure_ascii=False)
    except Exception:
        pass

def lgbm_add_sample(setup: Dict[str, Any], result: float):
    """
    Adiciona uma amostra de treino (setup + resultado).
    result > 0 = WIN (1), result < 0 = LOSS (0), result = 0 = ignora
    """
    global lgbm_data, lgbm_trade_count
    if not LGBM_ON or result == 0:
        return
    
    features = lgbm_extract_features(setup).tolist()
    label = 1 if result > 0 else 0
    
    lgbm_data.append({"features": features, "label": label, "timestamp": time.time()})
    lgbm_trade_count += 1
    
    # Limita dados a últimas 1000 amostras
    if len(lgbm_data) > 1000:
        lgbm_data = lgbm_data[-1000:]
    
    lgbm_save_data()
    
    # Retreina se atingiu threshold
    if lgbm_trade_count >= LGBM_RETRAIN_EVERY and len(lgbm_data) >= LGBM_MIN_SAMPLES:
        lgbm_train()
        lgbm_trade_count = 0

def lgbm_train():
    """Treina ou retreina o modelo LightGBM com os dados acumulados."""
    global lgbm_model, lgbm_data, lgbm_reliable, lgbm_val_accuracy
    
    if not LGBM_ON or lgb is None or len(lgbm_data) < LGBM_MIN_SAMPLES:
        return
    
    try:
        # ===== LIMPEZA DE DADOS ANTIGOS =====
        # Remove amostras com mais de 12 horas - padrões OTC mudam rápido
        MAX_DATA_AGE_HOURS = 12
        cutoff_time = time.time() - (MAX_DATA_AGE_HOURS * 3600)
        
        old_count = len(lgbm_data)
        lgbm_data = [d for d in lgbm_data if d.get("timestamp", time.time()) >= cutoff_time]
        removed = old_count - len(lgbm_data)
        
        if removed > 0:
            log.info(paint(f"[LGBM] Limpeza: removidas {removed} amostras antigas (>{MAX_DATA_AGE_HOURS}h)", C.Y))
            lgbm_save_data()
        
        # Verifica se ainda tem amostras suficientes após limpeza
        if len(lgbm_data) < LGBM_MIN_SAMPLES:
            log.warning(paint(f"[LGBM] Após limpeza, apenas {len(lgbm_data)} amostras (mín={LGBM_MIN_SAMPLES}). Modelo desabilitado.", C.Y))
            lgbm_reliable = False
            lgbm_val_accuracy = 0.0
            lgbm_model = None
            return
        
        X = np.array([d["features"] for d in lgbm_data], dtype=np.float32)
        y = np.array([d["label"] for d in lgbm_data], dtype=np.int32)
        
        # Parâmetros otimizados para trading - ANTI-OVERFITTING
        params = {
            "objective": "binary",
            "metric": "binary_logloss",
            "boosting_type": "gbdt",
            "num_leaves": 8,           # REDUZIDO: menos complexidade = menos overfitting
            "max_depth": 3,            # REDUZIDO: árvores mais rasas generalizam melhor
            "learning_rate": 0.03,     # REDUZIDO: aprendizado mais lento = mais robusto
            "n_estimators": 80,        # REDUZIDO: menos árvores
            "min_child_samples": 10,   # AUMENTADO: precisa mais exemplos por folha
            "subsample": 0.7,          # REDUZIDO: mais dropout de amostras
            "colsample_bytree": 0.7,   # REDUZIDO: mais dropout de features
            "reg_alpha": 0.5,          # AUMENTADO: mais regularização L1
            "reg_lambda": 0.5,         # AUMENTADO: mais regularização L2
            "verbose": -1,
            "force_col_wise": True,
        }
        
        lgbm_model = lgb.LGBMClassifier(**params)
        
        # VALIDAÇÃO REAL: divide dados em treino/teste para medir accuracy real
        n_samples = len(X)
        if n_samples >= 50:
            # 80/20 split - últimas amostras como validação (mais recentes)
            split_idx = int(n_samples * 0.8)
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            
            lgbm_model.fit(X_train, y_train)
            
            # Accuracy no treino
            preds_train = lgbm_model.predict(X_train)
            acc_train = (preds_train == y_train).mean() * 100
            
            # Accuracy na VALIDAÇÃO (accuracy real!)
            preds_val = lgbm_model.predict(X_val)
            acc_val = (preds_val == y_val).mean() * 100
            
            lgbm_val_accuracy = acc_val
            
            log.info(paint(f"[LGBM] Modelo treinado! Amostras={n_samples} | Treino={acc_train:.1f}% | Val={acc_val:.1f}% (real)", C.G))
            
            # ===== AUTO-DISABLE: se validação < 55%, modelo está chutando =====
            if acc_val < 55.0:
                lgbm_reliable = False
                log.warning(paint(f"[LGBM] ⚠️ Val={acc_val:.1f}% < 55% → LGBM DESABILITADO (usando só Bayes)", C.Y))
                log.warning(paint(f"[LGBM] Modelo não consegue prever melhor que moeda. Ignorando predições LGBM.", C.Y))
            else:
                lgbm_reliable = True
                log.info(paint(f"[LGBM] ✅ Val={acc_val:.1f}% ≥ 55% → LGBM CONFIÁVEL, usando no ensemble", C.G))
            
            # Retreina com TODOS os dados para o modelo final (só se confiável)
            if lgbm_reliable:
                lgbm_model.fit(X, y)
            else:
                # Modelo não confiável - mantém treinado mas marcado como unreliable
                lgbm_model.fit(X, y)
        else:
            # Poucas amostras: treina tudo mas marca como não confiável
            lgbm_model.fit(X, y)
            preds = lgbm_model.predict(X)
            acc = (preds == y).mean() * 100
            lgbm_reliable = False  # Sem validação = não confiável
            lgbm_val_accuracy = 0.0
            log.info(paint(f"[LGBM] Modelo treinado! Amostras={n_samples} | Acc={acc:.1f}% (sem validação - LGBM não confiável)", C.Y))
        
        lgbm_save_model()
        
    except Exception as e:
        log.warning(f"[LGBM] Erro no treino: {e}")
        lgbm_reliable = False
        lgbm_val_accuracy = 0.0

def lgbm_predict(setup: Dict[str, Any]) -> Tuple[float, bool]:
    """
    Prediz probabilidade de WIN usando LightGBM.
    
    Returns:
        (probabilidade, modelo_disponivel)
    """
    global lgbm_model
    
    if not LGBM_ON or lgbm_model is None:
        return 0.5, False
    
    try:
        features = lgbm_extract_features(setup).reshape(1, -1)
        proba = lgbm_model.predict_proba(features)[0]
        # proba[1] = probabilidade de WIN (classe 1)
        return float(proba[1]), True
    except Exception as e:
        log.warning(f"[LGBM] Erro na predição: {e}")
        return 0.5, False

# ===================== ENSEMBLE: BAYESIANO + LIGHTGBM =====================

def ensemble_predict(ativo: str, setup: Dict[str, Any], stats: Dict[str, Any]) -> Dict[str, Any]:
    """
    Combina predições do Bayesiano e LightGBM para decisão mais robusta.
    
    Modes:
    - "both": Ambos devem aprovar (mais conservador)
    - "any": Qualquer um aprova (mais agressivo)
    - "weighted": Média ponderada das probabilidades
    
    Returns:
        {
            "should_trade": bool,
            "bayes_prob": float,
            "lgbm_prob": float,
            "ensemble_prob": float,
            "reason": str
        }
    """
    # Predição Bayesiana
    bayes_pred = ai_predict(ativo, setup, stats)
    bayes_prob = float(bayes_pred["prob"])
    bayes_conf = float(bayes_pred["conf"])
    n_arm = int(bayes_pred["n_arm"])
    
    # Predição LightGBM
    lgbm_prob, lgbm_available = lgbm_predict(setup)
    
    # Se LightGBM não disponível OU não confiável (val < 55%), usa só Bayesiano
    if not lgbm_available or not LGBM_ON or not lgbm_reliable:
        reason_detail = "lgbm_off" if not LGBM_ON else ("lgbm_unreliable" if not lgbm_reliable else "lgbm_unavailable")
        should_trade = (bayes_prob >= AI_MIN_PROB) and (bayes_conf >= AI_CONF_MIN or n_arm < AI_MIN_SAMPLES)
        return {
            "should_trade": should_trade,
            "bayes_prob": bayes_prob,
            "lgbm_prob": 0.5,
            "ensemble_prob": bayes_prob,
            "reason": f"bayes_only({reason_detail},prob={bayes_prob:.2f})"
        }
    
    # Calcula probabilidade ensemble (média ponderada)
    # Bayesiano tem peso maior se tiver mais amostras
    bayes_weight = min(1.0, n_arm / AI_MIN_SAMPLES) * 0.5 + 0.25  # 0.25 a 0.75
    lgbm_weight = 1.0 - bayes_weight
    ensemble_prob = bayes_prob * bayes_weight + lgbm_prob * lgbm_weight
    
    # Decisão baseada no modo
    if ENSEMBLE_MODE == "both":
        # Ambos devem aprovar
        bayes_ok = bayes_prob >= AI_MIN_PROB
        lgbm_ok = lgbm_prob >= LGBM_MIN_PROB
        should_trade = bayes_ok and lgbm_ok
        reason = f"both(B={bayes_prob:.2f},L={lgbm_prob:.2f})"
    elif ENSEMBLE_MODE == "any":
        # Qualquer um aprova, MAS ensemble deve ser minimamente viável
        bayes_ok = bayes_prob >= AI_MIN_PROB
        lgbm_ok = lgbm_prob >= LGBM_MIN_PROB
        should_trade = (bayes_ok or lgbm_ok) and ensemble_prob >= 0.48
        reason = f"any(B={bayes_prob:.2f},L={lgbm_prob:.2f},ens={ensemble_prob:.2f})"
    else:  # weighted
        # Usa prob ensemble
        should_trade = ensemble_prob >= AI_MIN_PROB
        reason = f"weighted(ens={ensemble_prob:.2f})"
    
    # Warmup: se poucos dados no Bayesiano, IA decide com base no cenário
    if n_arm < AI_MIN_SAMPLES:
        warmup_threshold = LGBM_WARMUP_PROB if IA_MODE == "learning" else LGBM_MIN_PROB
        if lgbm_available:
            # Pegar contexto do setup para ajustar exigência
            ctx_val = float(setup.get("market_quality", 0.40))
            entry_conf_val = float(setup.get("entry_confidence", 0.50))
            sr_prox = float(setup.get("sr_proximity", 0.0))
            sr_tq = int(setup.get("sr_touches", 0))
            
            # Threshold dinâmico de ensemble baseado no contexto
            if ctx_val < 0.40:  # contexto ruim
                min_ens = ENS_MIN_CTX_RUIM  # 0.58
            elif ctx_val < 0.50:  # contexto mediano
                min_ens = ENS_MIN_CTX_MED   # 0.54
            else:  # contexto bom
                min_ens = ENS_MIN_CTX_BOM   # 0.50
            
            # entry_conf baixo (0.44) penaliza mais
            if entry_conf_val < 0.50:
                min_ens += 0.02
            
            # S/R PROXIMITY BENEFIT: pullback perto de S/R forte relaxa threshold
            # (estilo Candle Mind: S/R forte = mais confiança na entrada)
            if sr_prox > 0.60 and sr_tq >= 4:
                min_ens -= 0.06  # suporte/resistência muito forte
            elif sr_prox > 0.40 and sr_tq >= 3:
                min_ens -= 0.03  # suporte/resistência moderado
            
            # REGRA #1: LGBM muito confiante que vai PERDER
            if lgbm_prob < 0.30:
                should_trade = False
                reason = f"warmup_danger(L={lgbm_prob:.2f}<0.30)"
            # REGRA #2: Ambos negativos = consenso de LOSS, bloquear
            elif bayes_prob < 0.50 and lgbm_prob < 0.50:
                should_trade = False
                reason = f"warmup_consenso_neg(B={bayes_prob:.2f},L={lgbm_prob:.2f})"
            # REGRA #3: Ambos modelos concordam positivamente (ambos >= 0.55)
            elif bayes_prob >= 0.55 and lgbm_prob >= 0.55:
                should_trade = True
                reason = f"warmup_consenso_ok(B={bayes_prob:.2f},L={lgbm_prob:.2f})"
            # REGRA #4: Bayes alto (>=0.60) mas LGBM não tão contra (>=0.45)
            elif bayes_prob >= 0.60 and lgbm_prob >= 0.45:
                should_trade = True
                reason = f"warmup_bayes_forte(B={bayes_prob:.2f},L={lgbm_prob:.2f})"
            # REGRA #5: LGBM alto (>=0.58) mas Bayes não tão contra (>=0.45)
            elif lgbm_prob >= 0.58 and bayes_prob >= 0.45:
                should_trade = True
                reason = f"warmup_lgbm_forte(B={bayes_prob:.2f},L={lgbm_prob:.2f})"
            # REGRA #6: Ensemble atinge threshold dinâmico (ajustado por contexto)
            elif ensemble_prob >= min_ens:
                should_trade = True
                reason = f"warmup_ens_ctx(B={bayes_prob:.2f},L={lgbm_prob:.2f},ens={ensemble_prob:.2f},min={min_ens:.2f})"
            else:
                # Cenário fraco demais
                should_trade = False
                reason = f"warmup_fraco(B={bayes_prob:.2f},L={lgbm_prob:.2f},ens={ensemble_prob:.2f},min={min_ens:.2f})"
        else:
            should_trade = True
            reason = f"warmup_no_lgbm"
    
    return {
        "should_trade": should_trade,
        "bayes_prob": bayes_prob,
        "lgbm_prob": lgbm_prob,
        "ensemble_prob": ensemble_prob,
        "reason": reason,
        "bayes_conf": bayes_conf,
        "n_arm": n_arm
    }

# ===================== IA BAYESIANA (ORIGINAL) =====================

def _clip(x: float, lo: float, hi: float) -> float:
    return float(max(lo, min(hi, x)))

def _bucket(x: float, step: float, lo: float, hi: float) -> int:
    x = _clip(x, lo, hi)
    return int(round((x - lo) / step))

def ai_make_key(ativo: str, setup: Dict[str, Any]) -> str:
    """
    Chave compacta MELHORADA para análise mais inteligente:
    - direção
    - score (buckets mais refinados)
    - pb_len (tamanho do pullback)
    - retr (retração)
    - A_atr (força do impulso)
    - effA (eficiência do impulso A - NOVO)
    - flips (chopiness - NOVO)
    - distBreak (distância da quebra - NOVO)
    """
    d = str(setup.get("dir", "NEUTRAL"))
    sc = float(setup.get("score", 0.0))
    pb = int(setup.get("pb_len", 0))
    retr = float(setup.get("retr", 0.0))
    Aatr = float(setup.get("A_atr", 0.0))
    effA = float(setup.get("effA", 0.0))
    flips = float(setup.get("flips", 0.0))
    distBreak = float(setup.get("distBreak", 0.0))

    # Buckets mais refinados para melhor precisão
    b_sc = _bucket(sc, 0.04, 0.40, 1.00)        # 0.40..1.00, passo menor
    b_re = _bucket(retr, 0.06, 0.10, 0.80)      # 0.10..0.80, mais granular
    b_A  = _bucket(Aatr, 0.40, 0.60, 6.00)      # 0.60..6.00
    b_eff = _bucket(effA, 0.08, 0.50, 1.00)     # eficiência NOVO
    b_flip = _bucket(flips, 0.10, 0.0, 0.80)    # chopiness NOVO
    b_dist = _bucket(distBreak, 0.05, 0.0, 0.50) # distância da quebra NOVO

    return f"{d}|sc{b_sc}|pb{pb}|re{b_re}|A{b_A}|eff{b_eff}|fl{b_flip}|dst{b_dist}"

def ai_prior_from_setup(setup: Dict[str, Any]) -> float:
    """
    Prior INTELIGENTE baseado em múltiplos fatores (não apenas score).
    Analisa confluência de sinais para melhor estimativa inicial.
    """
    sc = float(setup.get("score", 0.0))
    effA = float(setup.get("effA", 0.0))
    flips = float(setup.get("flips", 0.5))
    retr = float(setup.get("retr", 0.5))
    distBreak = float(setup.get("distBreak", 0.2))

    # Base no score
    p = 0.50 + (sc - 0.50) * 0.35

    # Ajustes inteligentes por confluência:
    # 1. Eficiência alta do impulso A aumenta confiança
    if effA > 0.70:
        p += 0.04
    elif effA < 0.60:
        p -= 0.03

    # 2. Baixo chopiness (mercado direcional) aumenta confiança
    if flips < 0.35:
        p += 0.05
    elif flips > 0.55:
        p -= 0.04

    # 3. Retração ideal (0.3-0.5) aumenta confiança
    if 0.30 <= retr <= 0.50:
        p += 0.04
    elif retr < 0.20 or retr > 0.65:
        p -= 0.03

    # 4. Quebra próxima e limpa aumenta confiança
    if distBreak < 0.15:
        p += 0.03
    elif distBreak > 0.25:
        p -= 0.02

    return _clip(p, 0.40, 0.75)

def ai_predict(ativo: str, setup: Dict[str, Any], stats: Dict[str, Any]) -> Dict[str, float]:
    """
    Retorna: prob, bayes_mean, ucb01, conf, n_arm, total
    """
    key = ai_make_key(ativo, setup)
    arms = stats.setdefault("arms", {})
    meta = stats.setdefault("meta", {"total": 0})

    total = int(meta.get("total", 0))
    arm = arms.get(key)

    prior = ai_prior_from_setup(setup)

    if arm is None:
        # inicia com Beta fraca baseada no prior (a+b = 2)
        a = 2.0 * prior
        b = 2.0 * (1.0 - prior)
        n = 0
        arms[key] = {"a": a, "b": b, "n": n}
        bayes_mean = a / (a + b)
        ucb01 = 1.0
        conf = float(_clip(0.55 + float(setup.get("score", 0.0)) * 0.30, 0.0, 0.90))
        return {"prob": float(bayes_mean), "bayes": float(bayes_mean), "ucb01": float(ucb01),
                "conf": float(conf), "n_arm": 0, "total": total, "key": key, "prior": prior}

    a = float(arm.get("a", 1.0))
    b = float(arm.get("b", 1.0))
    n = int(arm.get("n", 0))

    bayes_mean = a / (a + b)

    # UCB simples em [0..1]
    if n <= 0:
        ucb01 = 1.0
    else:
        bonus = math.sqrt(2.0 * math.log(max(2, total + 1)) / max(1, n))
        ucb01 = _clip(bayes_mean + bonus, 0.0, 1.0)

    # confiança cresce com amostras
    conf = _clip(n / (n + 10.0), 0.0, 0.99)

    # prob final mistura prior + bayes, mas com peso maior no bayes quando tem histórico
    w = _clip(n / (n + 25.0), 0.0, 1.0)
    prob = (1.0 - w) * prior + w * bayes_mean
    prob = _clip(prob, 0.0, 1.0)

    return {"prob": float(prob), "bayes": float(bayes_mean), "ucb01": float(ucb01),
            "conf": float(conf), "n_arm": n, "total": total, "key": key, "prior": prior}

def ai_update(ativo: str, setup: Dict[str, Any], pnl: float, stats: Dict[str, Any]):
    """
    pnl > 0 => sucesso
    pnl < 0 => falha
    pnl = 0 => ignora

    ATUALIZA: Bayesian (a, b, n) + Rastreamento de padrão (wins, losses, trades)
    """
    if pnl == 0:
        return

    key = ai_make_key(ativo, setup)
    arms = stats.setdefault("arms", {})
    meta = stats.setdefault("meta", {"total": 0})
    patterns = stats.setdefault("patterns", {})  # NOVO: rastreamento de padrões

    arm = arms.get(key)
    if arm is None:
        prior = ai_prior_from_setup(setup)
        arms[key] = {"a": 2.0 * prior, "b": 2.0 * (1.0 - prior), "n": 0}
        arm = arms[key]

    # Atualiza Bayesian
    a = float(arm.get("a", 1.0))
    b = float(arm.get("b", 1.0))
    n = int(arm.get("n", 0))

    if pnl > 0:
        a += 1.0
    else:
        b += 1.0

    n += 1
    arm["a"], arm["b"], arm["n"] = a, b, n
    meta["total"] = int(meta.get("total", 0)) + 1

    # NOVO: Rastreamento de padrão para bloqueio inteligente
    pattern = patterns.get(key)
    if pattern is None:
        patterns[key] = {"trades": 0, "wins": 0, "losses": 0}
        pattern = patterns[key]

    pattern["trades"] += 1
    if pnl > 0:
        pattern["wins"] += 1
    else:
        pattern["losses"] += 1

def ai_retrain_on_loss(ativo: str, setup: Dict[str, Any], stats: Dict[str, Any]):
    """
    RETREINO SEVERO: Aplica penalidade extra no padrão que causou LOSS.
    
    - Aumenta 'b' (falhas) no Bayesian em proporção ao RETRAIN_PENALTY
    - Marca padrão como arriscado para evitar entrada imediata igual
    - Salva imediatamente para persistir aprendizado
    """
    key = ai_make_key(ativo, setup)
    arms = stats.setdefault("arms", {})
    patterns = stats.setdefault("patterns", {})
    
    arm = arms.get(key)
    if arm is None:
        prior = ai_prior_from_setup(setup)
        arms[key] = {"a": 2.0 * prior, "b": 2.0 * (1.0 - prior), "n": 0}
        arm = arms[key]
    
    # PENALIDADE SEVERA: aumenta 'b' (falhas) significativamente
    # Isso reduz a probabilidade bayesiana do padrão
    penalty_factor = max(1, int(RETRAIN_PENALTY * 10))  # Ex: 0.25 -> 2.5 -> 2 falhas extras
    arm["b"] = float(arm.get("b", 1.0)) + penalty_factor
    
    # Marcar padrão como "queimado" temporariamente
    pattern = patterns.get(key)
    if pattern is None:
        patterns[key] = {"trades": 0, "wins": 0, "losses": 0, "burned_until": 0}
        pattern = patterns[key]
    
    # Queimar padrão por 30 minutos (evita repetir mesmo erro)
    pattern["burned_until"] = time.time() + 1800  # 30 min
    pattern["last_loss_time"] = time.time()
    
    # Log detalhado do retreino
    new_prob = arm.get("a", 1.0) / (arm.get("a", 1.0) + arm["b"])
    log.warning(f"[AI-RETRAIN] {ativo} key={key[:30]}... | penalidade={penalty_factor} | nova_prob={new_prob:.2f}")

def ai_learn_from_backtest_signal(ativo: str, setup: Dict[str, Any], win: bool, stats: Dict[str, Any]):
    """
    APRENDIZADO COM BACKTEST: Atualiza a IA com sinais simulados do backtest.
    Usa peso reduzido (AI_BACKTEST_WEIGHT) para não dominar trades reais.
    """
    if not AI_LEARN_FROM_BACKTEST:
        return
    
    key = ai_make_key(ativo, setup)
    arms = stats.setdefault("arms", {})
    patterns = stats.setdefault("patterns", {})
    
    arm = arms.get(key)
    if arm is None:
        prior = ai_prior_from_setup(setup)
        arms[key] = {"a": 2.0 * prior, "b": 2.0 * (1.0 - prior), "n": 0}
        arm = arms[key]
    
    # Aplicar peso do backtest (menor que trades reais)
    weight = AI_BACKTEST_WEIGHT
    
    if win:
        arm["a"] = float(arm.get("a", 1.0)) + weight
    else:
        arm["b"] = float(arm.get("b", 1.0)) + weight
    
    arm["n"] = int(arm.get("n", 0)) + 1
    
    # Atualizar padrão
    pattern = patterns.get(key)
    if pattern is None:
        patterns[key] = {"trades": 0, "wins": 0, "losses": 0, "backtest_samples": 0}
        pattern = patterns[key]
    
    pattern["backtest_samples"] = pattern.get("backtest_samples", 0) + 1
    if win:
        pattern["wins"] = pattern.get("wins", 0) + 1
    else:
        pattern["losses"] = pattern.get("losses", 0) + 1

def ai_learn_from_backtest_batch(sinais: List[Dict], stats: Dict[str, Any]):
    """
    Processa um lote de sinais do backtest e atualiza a IA.
    Retorna quantidade de sinais processados.
    """
    if not AI_LEARN_FROM_BACKTEST or not sinais:
        return 0
    
    count = 0
    for sinal in sinais:
        ativo = sinal.get("ativo", "")
        win = sinal.get("win", False)
        
        # Reconstruir setup completo para gerar a key e features corretas
        setup_backtest = {
            "dir": sinal.get("direcao", "CALL"),
            "score": sinal.get("score", 0.5),
            "market_quality": sinal.get("ctx", 0.5),
            "effA": sinal.get("effA", 0.3),
            "has_lt": sinal.get("has_lt", False),
            "retracement": sinal.get("retr", 0.5),
            "pullback_candles": sinal.get("pb", 2),
            "entry_confirmation": sinal.get("entry_conf", 0.5),
            "lt_confluence": sinal.get("lt_conf", 0),
        }
        
        ai_learn_from_backtest_signal(ativo, setup_backtest, win, stats)
        
        # Também adiciona ao LightGBM se disponível
        if LGBM_ON and lgb is not None:
            lgbm_add_sample_from_backtest(setup_backtest, win)
        
        count += 1
    
    return count

def lgbm_add_sample_from_backtest(setup: Dict[str, Any], win: bool):
    """
    Adiciona amostra do backtest ao LightGBM com peso reduzido.
    """
    global lgbm_data
    if not LGBM_ON:
        return
    
    features = lgbm_extract_features(setup).tolist()
    label = 1 if win else 0
    
    # Adiciona com flag de backtest e timestamp
    lgbm_data.append({"features": features, "label": label, "source": "backtest", "timestamp": time.time()})
    
    # Limita dados
    if len(lgbm_data) > 1000:
        lgbm_data = lgbm_data[-1000:]
    
    lgbm_save_data()

# ===================== HISTÓRICO DE BACKTEST COM DECAY TEMPORAL =====================
# Armazena sinais de backtests anteriores para aumentar assertividade

backtest_history: List[Dict] = []

def backtest_history_load():
    """Carrega histórico de backtests do disco."""
    global backtest_history
    try:
        if os.path.exists(BACKTEST_HISTORY_FILE):
            with open(BACKTEST_HISTORY_FILE, "r", encoding="utf-8") as f:
                backtest_history = json.load(f)
            log.info(f"[BACKTEST-HIST] Carregado histórico com {len(backtest_history)} amostras")
    except Exception as e:
        backtest_history = []
        log.warning(f"[BACKTEST-HIST] Erro ao carregar: {e}")

def backtest_history_save():
    """Salva histórico de backtests no disco."""
    global backtest_history
    try:
        with open(BACKTEST_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(backtest_history, f, ensure_ascii=False)
    except Exception:
        pass

def backtest_history_calculate_weight(timestamp: float) -> float:
    """
    Calcula o peso de uma amostra baseado na idade (decay temporal).
    - Amostras recentes (< DECAY_HOURS): peso = 1.0
    - Amostras antigas: peso decai linearmente até MIN_WEIGHT
    """
    age_seconds = time.time() - timestamp
    age_hours = age_seconds / 3600
    
    if age_hours <= BACKTEST_HISTORY_DECAY_HOURS:
        return 1.0
    
    # Decay linear após DECAY_HOURS horas
    # Em 24h, chega ao peso mínimo
    decay_range = 24.0 - BACKTEST_HISTORY_DECAY_HOURS
    excess_hours = age_hours - BACKTEST_HISTORY_DECAY_HOURS
    decay_factor = min(1.0, excess_hours / decay_range)
    
    weight = 1.0 - (decay_factor * (1.0 - BACKTEST_HISTORY_MIN_WEIGHT))
    return max(BACKTEST_HISTORY_MIN_WEIGHT, weight)

def backtest_history_add_signals(sinais: List[Dict]):
    """
    Adiciona sinais do backtest atual ao histórico acumulado.
    Remove amostras antigas se exceder o limite.
    """
    global backtest_history
    
    if not BACKTEST_USE_ACCUMULATED:
        return
    
    timestamp = time.time()
    
    # Adicionar novos sinais com timestamp
    for sinal in sinais:
        sinal_with_ts = sinal.copy()
        sinal_with_ts["timestamp"] = timestamp
        backtest_history.append(sinal_with_ts)
    
    # Remover amostras muito antigas (>48h) e limitar tamanho
    cutoff_time = time.time() - (48 * 3600)  # 48 horas
    backtest_history = [s for s in backtest_history if s.get("timestamp", 0) > cutoff_time]
    
    # Limitar ao máximo de amostras (mantém as mais recentes)
    if len(backtest_history) > BACKTEST_HISTORY_MAX_SAMPLES:
        backtest_history = sorted(backtest_history, key=lambda x: x.get("timestamp", 0), reverse=True)
        backtest_history = backtest_history[:BACKTEST_HISTORY_MAX_SAMPLES]
    
    backtest_history_save()
    log.info(f"[BACKTEST-HIST] Histórico atualizado: {len(backtest_history)} amostras")

def backtest_history_get_weighted_signals() -> List[Tuple[Dict, float]]:
    """
    Retorna todos os sinais do histórico com seus pesos calculados.
    Returns: Lista de (sinal, peso)
    """
    global backtest_history
    
    if not BACKTEST_USE_ACCUMULATED or not backtest_history:
        return []
    
    weighted_signals = []
    for sinal in backtest_history:
        ts = sinal.get("timestamp", time.time())
        weight = backtest_history_calculate_weight(ts)
        weighted_signals.append((sinal, weight))
    
    return weighted_signals

def backtest_history_analyze() -> Dict[str, Any]:
    """
    Analisa o histórico de backtest e retorna estatísticas.
    """
    global backtest_history
    
    if not backtest_history:
        return {"total": 0, "wins": 0, "winrate": 0, "weighted_winrate": 0}
    
    total = len(backtest_history)
    wins = sum(1 for s in backtest_history if s.get("win", False))
    
    # Calcular winrate ponderado pelo tempo
    total_weight = 0
    wins_weight = 0
    for sinal in backtest_history:
        ts = sinal.get("timestamp", time.time())
        weight = backtest_history_calculate_weight(ts)
        total_weight += weight
        if sinal.get("win", False):
            wins_weight += weight
    
    weighted_winrate = (wins_weight / total_weight) if total_weight > 0 else 0
    
    return {
        "total": total,
        "wins": wins,
        "winrate": wins / total if total > 0 else 0,
        "weighted_winrate": weighted_winrate,
        "total_weight": total_weight
    }

def ai_learn_from_accumulated_history(stats: Dict[str, Any]) -> int:
    """
    Treina a IA com o histórico acumulado de backtests, aplicando peso temporal.
    Usa peso decrescente para amostras antigas.
    
    Returns: Número de amostras processadas
    """
    global backtest_history
    
    if not AI_LEARN_FROM_BACKTEST or not BACKTEST_USE_ACCUMULATED:
        return 0
    
    if not backtest_history:
        backtest_history_load()
    
    if not backtest_history:
        return 0
    
    count = 0
    for sinal, time_weight in backtest_history_get_weighted_signals():
        ativo = sinal.get("ativo", "")
        win = sinal.get("win", False)
        
        # Peso final = peso do backtest * peso temporal
        final_weight = AI_BACKTEST_WEIGHT * time_weight
        
        # Reconstruir setup
        setup_backtest = {
            "dir": sinal.get("direcao", "CALL"),
            "score": sinal.get("score", 0.5),
            "market_quality": sinal.get("ctx", 0.5),
            "effA": sinal.get("effA", 0.3),
            "has_lt": sinal.get("has_lt", False),
            "retracement": sinal.get("retr", 0.5),
            "pullback_candles": sinal.get("pb", 2),
            "entry_confirmation": sinal.get("entry_conf", 0.5),
            "lt_confluence": sinal.get("lt_conf", 0),
        }
        
        # Atualizar Bayesian com peso ajustado
        key = ai_make_key(ativo, setup_backtest)
        arms = stats.setdefault("arms", {})
        
        arm = arms.get(key)
        if arm is None:
            prior = ai_prior_from_setup(setup_backtest)
            arms[key] = {"a": 2.0 * prior, "b": 2.0 * (1.0 - prior), "n": 0}
            arm = arms[key]
        
        if win:
            arm["a"] = float(arm.get("a", 1.0)) + final_weight
        else:
            arm["b"] = float(arm.get("b", 1.0)) + final_weight
        
        arm["n"] = int(arm.get("n", 0)) + 1
        count += 1
    
    return count

def ai_should_block_pattern(ativo: str, setup: Dict[str, Any], stats: Dict[str, Any]) -> Tuple[bool, str]:
    """
    DECISÃO INTELIGENTE: Bloqueia padrão SOMENTE se histórico mostra losses consistentes.
    Permite padrões durante fase de aprendizado e padrões com winrate aceitável.

    Returns:
        (should_block, reason)
    """
    key = ai_make_key(ativo, setup)
    patterns = stats.get("patterns", {})
    pattern = patterns.get(key)

    # Fase 0: PADRÃO QUEIMADO - bloqueia temporariamente após LOSS com retreino
    if pattern and pattern.get("burned_until", 0) > time.time():
        remaining = int(pattern["burned_until"] - time.time())
        return True, f"burned({remaining}s_restantes)"

    # Fase 1: APRENDIZADO - permite tudo (sem histórico suficiente)
    if pattern is None or pattern["trades"] < AI_MIN_SAMPLES:
        trades_count = pattern["trades"] if pattern else 0
        return False, f"learning({trades_count}/{AI_MIN_SAMPLES})"

    # Fase 2: AVALIAÇÃO - analisa performance real
    winrate = pattern["wins"] / max(1, pattern["trades"])

    # Bloqueia SOMENTE se winrate consistentemente BAIXO
    if winrate < AI_MIN_WINRATE:
        return True, f"blocked_wr={winrate:.0%}({pattern['wins']}W/{pattern['losses']}L)"

    # Permite: padrão tem performance aceitável ou está em zona cinza
    return False, f"approved_wr={winrate:.0%}({pattern['wins']}W/{pattern['losses']}L)"

# ===================== PERNADA B =====================
def pernada_b(df_m1: pd.DataFrame, atr_val: float) -> Dict[str, Any]:
    if len(df_m1) < 150:  # Reduzido de 240 para 150 para mais oportunidades
        return {"trade": False, "dir": "NEUTRAL", "score": 0.0, "reasons": ["poucas_velas"]}

    # ANÁLISE INTELIGENTE DE CONTEXTO
    context = analyze_market_context(df_m1, atr_val)
    market_quality = float(context.get("quality", 0.0))

    flips_frac, eff_zone = chop_stats(df_m1, CHOP_LOOKBACK)
    comp = compression_ratio(df_m1, atr_val, COMP_LOOKBACK)
    late_ext = late_extension_atr(df_m1, atr_val, LATE_LOOKBACK)

    decision = df_m1.iloc[-1]
    q = wick_fractions(decision)

    # No modo LEARNING, só avisos mas não bloqueia
    warning_gatilho = None
    warning_pingpong = None
    
    if q["body_frac"] < MIN_BODY_FRAC_BREAK:
        if IA_MODE != "learning":
            return {"trade": False, "dir": "NEUTRAL", "score": 0.0,
                    "reasons": [f"gatilho_fraco(body={q['body_frac']:.2f})"]}
        else:
            warning_gatilho = f"gatilho_fraco(body={q['body_frac']:.2f})"

    # corredor de SR perto do preço => evita operar (só no modo strict)
    ping = sr_pingpong_zone(df_m1, atr_val)
    if ping:
        if IA_MODE != "learning":
            return {"trade": False, "dir": "NEUTRAL", "score": 0.0, "reasons": [ping]}
        else:
            warning_pingpong = ping

    best = None

    for pb_len in range(PULLBACK_MIN, PULLBACK_MAX + 1):
        pb = df_m1.iloc[-(pb_len + 1):-1]
        if len(pb) != pb_len:
            continue

        for w in range(IMPULSO_JANELA_MIN, IMPULSO_JANELA_MAX + 1):
            imp = df_m1.iloc[-(pb_len + 1 + w):-(pb_len + 1)]
            if len(imp) != w:
                continue

            top = float(imp["high"].max())
            bot = float(imp["low"].min())
            size_A = top - bot

            if size_A < IMPULSO_MIN_ATR * atr_val:
                continue

            start = float(imp["open"].iloc[0])
            end = float(imp["close"].iloc[-1])
            move = end - start

            # A direção da PERNADA A define a tendência principal
            dir_impulso_A = "PUT" if move < 0 else ("CALL" if move > 0 else "NEUTRAL")
            if dir_impulso_A == "NEUTRAL":
                continue

            eff_A = leg_efficiency(imp)
            # No modo learning, aceita eficiência um pouco mais baixa (mas não muito)
            min_eff = MIN_EFF_A if IA_MODE != "learning" else 0.20  # MUITO relaxado no learning
            if eff_A < min_eff:
                continue

            # O pullback deve ser CONTRA a pernada A
            contra = 0
            for _, r in pb.iterrows():
                d = candle_dir(r)
                if dir_impulso_A == "PUT" and d == 1:
                    contra += 1
                if dir_impulso_A == "CALL" and d == -1:
                    contra += 1

            # No modo learning, exige menos velas contra (muito relaxado)
            min_contra_pct = 0.50 if IA_MODE != "learning" else 0.25
            if contra < max(1, int(math.ceil(pb_len * min_contra_pct))):
                continue

            # Verifica continuação de tendência
            impulse_start_idx = len(df_m1) - (pb_len + 1 + w)
            trend_validation = validate_trend_continuation(df_m1, dir_impulso_A, impulse_start_idx)
            trend_strength = float(trend_validation.get("strength", 0.0)) if trend_validation.get("valid", False) else 0.0

            # Calcula a retração do pullback
            if dir_impulso_A == "PUT":
                pb_high = float(pb["high"].max())
                retr = (pb_high - bot) / max(size_A, 1e-9)
            else:
                pb_low = float(pb["low"].min())
                retr = (top - pb_low) / max(size_A, 1e-9)

            if retr < RETR_MIN or retr > RETR_MAX:
                continue

            c1 = float(decision["close"])
            dir_entrada = dir_impulso_A

            # bloqueio SR forte (desabilitado no modo learning)
            if IA_MODE != "learning":
                blk_sr = sr_block_directional_multi(df_m1, atr_val, dir_entrada)
                if blk_sr:
                    continue

            pb_high = float(pb["high"].max())
            pb_low = float(pb["low"].min())

            if dir_entrada == "CALL":
                if not (c1 > pb_low + BREAK_MARGIN_ATR * atr_val):
                    continue
                # No modo learning, permite mais pavio contra
                max_wick = MAX_WICK_AGAINST if IA_MODE != "learning" else 0.90
                if q["upper_frac"] > max_wick:
                    continue

                dist = (c1 - pb_low) / max(atr_val, 1e-9)
                # No modo learning, permite distância maior
                max_dist = MAX_BREAK_DISTANCE_ATR if IA_MODE != "learning" else 0.80
                if dist > max_dist:
                    continue

                entry_validation = validate_entry_quality(df_m1, atr_val, "CALL", c1, pb_high, pb_low)
                # No modo learning, não bloqueia por validação de entrada
                if IA_MODE != "learning" and not entry_validation.get("valid", False):
                    continue

                entry_confidence = float(entry_validation.get("confidence", 0.0))
                risk_atr = float(entry_validation.get("risk_atr", 0.0))
                entry_momentum = float(entry_validation.get("momentum", 0.0))
                entry_alignment = float(entry_validation.get("alignment", 0.0))

                lt_conf = check_trendline_confluence(df_m1, pb_high, pb_low, "CALL", atr_val)
                lt_confluence = float(lt_conf.get("confluence", 0.0))
                has_lt = lt_conf.get("has_trendline", False)

                # S/R PROXIMITY (estilo Candle Mind) - pullback tocou suporte?
                sr_info = sr_proximity_score(df_m1, atr_val, "CALL", pb_high, pb_low)
                sr_bonus = float(sr_info["sr_bonus"])
                sr_proximity = float(sr_info["sr_proximity"])
                sr_touches = int(sr_info["sr_touches"])

                # Score base
                score = 0.40  # Base aumentada

                impulso_score = min(0.12, (size_A / atr_val - IMPULSO_MIN_ATR) * 0.06)
                score += impulso_score

                eff_score = min(0.15, max(0, (eff_A - MIN_EFF_A) * 0.35))
                score += eff_score

                if 0.30 <= retr <= 0.50:
                    retr_score = 0.12
                elif 0.25 <= retr <= 0.60:
                    retr_score = 0.05
                else:
                    retr_score = max(-0.08, -(abs(retr - 0.40) * 0.20))
                score += retr_score

                if 2 <= pb_len <= 4:
                    pb_score = 0.06
                elif pb_len == 1 or pb_len == 5:
                    pb_score = 0.02
                else:
                    pb_score = -0.02
                score += pb_score

                if flips_frac > 0.50:
                    chop_penalty = min(0.20, (flips_frac - 0.50) * 0.50)
                    score -= chop_penalty

                # Contexto de mercado - MUITO IMPORTANTE
                if market_quality > 0.65:
                    ctx_score = 0.22
                elif market_quality > 0.55:
                    ctx_score = 0.12
                elif market_quality > 0.45:
                    ctx_score = 0.0
                else:
                    ctx_score = -0.30  # Penalidade SEVERA para contexto ruim
                score += ctx_score

                trend_score = min(0.08, trend_strength * 0.12)
                score += trend_score

                if entry_confidence > 0.65:
                    entry_score = 0.25
                elif entry_confidence > 0.55:
                    entry_score = 0.15
                elif entry_confidence > 0.48:
                    entry_score = 0.08
                else:
                    entry_score = -0.05
                score += entry_score

                momentum_score = min(0.10, entry_momentum * 0.08)
                score += momentum_score

                if entry_alignment >= 0.67:
                    align_score = 0.08
                elif entry_alignment >= 0.34:
                    align_score = 0.03
                else:
                    align_score = -0.03
                score += align_score

                if has_lt and lt_confluence > 0.8:
                    score += 0.25
                elif has_lt and lt_confluence > 0.5:
                    score += 0.15
                elif has_lt and lt_confluence > 0.2:
                    score += 0.05

                # BONUS S/R PROXIMITY (Candle Mind style) - suporte forte
                score += sr_bonus

                if risk_atr > 1.3:
                    risk_penalty = 0.10
                elif risk_atr > 1.0:
                    risk_penalty = 0.05
                elif risk_atr < 0.30:
                    risk_penalty = 0.05
                else:
                    risk_penalty = 0.0
                score -= risk_penalty

                perfect_count = 0
                if market_quality > 0.60: perfect_count += 1
                if eff_A > 0.70: perfect_count += 1
                if 0.30 <= retr <= 0.50: perfect_count += 1
                if entry_confidence > 0.65: perfect_count += 1
                if entry_alignment >= 0.67: perfect_count += 1
                if lt_confluence > 0.8: perfect_count += 1
                if sr_proximity > 0.50 and sr_touches >= 3: perfect_count += 1  # S/R confluência

                if perfect_count >= 5:
                    confluence_bonus = 0.20
                elif perfect_count >= 4:
                    confluence_bonus = 0.12
                elif perfect_count >= 3:
                    confluence_bonus = 0.05
                else:
                    confluence_bonus = 0.0

                score += confluence_bonus
                score = float(max(0.0, min(0.95, score)))

                # Filtros baseados no modo de operação
                if IA_MODE == "learning":
                    # Modo LEARNING: IA entende o cenário e decide
                    # Score mínimo baixo - IA aprende com entradas reais
                    if score < 0.42:
                        continue
                    # Contexto: só bloqueia se MUITO ruim
                    if market_quality < 0.25:
                        continue
                    # Confiança mínima relaxada
                    if entry_confidence < 0.35:
                        continue
                else:
                    # Modo STRICT: filtros rigorosos
                    if score < 0.60:
                        continue
                    if market_quality < 0.45:
                        continue
                    if entry_confidence < 0.50:
                        continue

                setup = {
                    "trade": True, "dir": "CALL", "score": score,
                    "pb_len": pb_len, "retr": float(retr),
                    "A_atr": float(size_A / max(atr_val, 1e-9)),
                    "effA": float(eff_A),
                    "flips": float(flips_frac),
                    "comp": float(comp),
                    "late": float(late_ext),
                    "distBreak": float(dist),
                    "market_quality": float(market_quality),
                    "context": str(context.get("context", "?")),
                    "confluence_bonus": float(confluence_bonus),
                    "trend_strength": float(trend_strength),
                    "trend_reason": str(trend_validation.get("reason", "?")),
                    "entry_confidence": float(entry_confidence),
                    "entry_momentum": float(entry_momentum),
                    "entry_alignment": float(entry_alignment),
                    "risk_atr": float(risk_atr),
                    "lt_confluence": float(lt_confluence),
                    "has_lt": has_lt,
                    "sr_proximity": float(sr_proximity),
                    "sr_bonus": float(sr_bonus),
                    "sr_touches": int(sr_touches),
                    "sr_reason": str(sr_info.get("sr_reason", "sem_sr")),
                    "reasons": [
                        "pernadaB_CALL",
                        f"A={size_A/atr_val:.2f}ATR", f"retr={retr:.2f}", f"pb={pb_len}",
                        f"effA={eff_A:.2f}",
                        f"ctx={context.get('context','?')}({market_quality:.2f})",
                        f"entry_conf={entry_confidence:.2f}",
                        f"LTA={lt_confluence:.2f}" if has_lt else "sem_LTA",
                        f"SR={sr_info.get('sr_reason','sem_sr')}" if sr_proximity > 0 else "sem_SR"
                    ]
                }
            else:  # PUT
                if not (c1 < pb_high - BREAK_MARGIN_ATR * atr_val):
                    continue
                # No modo learning, permite mais pavio contra
                max_wick = MAX_WICK_AGAINST if IA_MODE != "learning" else 0.90
                if q["lower_frac"] > max_wick:
                    continue

                dist = (pb_high - c1) / max(atr_val, 1e-9)
                # No modo learning, permite distância maior
                max_dist = MAX_BREAK_DISTANCE_ATR if IA_MODE != "learning" else 0.80
                if dist > max_dist:
                    continue

                entry_validation = validate_entry_quality(df_m1, atr_val, "PUT", c1, pb_high, pb_low)
                # No modo learning, não bloqueia por validação de entrada
                if IA_MODE != "learning" and not entry_validation.get("valid", False):
                    continue

                entry_confidence = float(entry_validation.get("confidence", 0.0))
                risk_atr = float(entry_validation.get("risk_atr", 0.0))
                entry_momentum = float(entry_validation.get("momentum", 0.0))
                entry_alignment = float(entry_validation.get("alignment", 0.0))

                lt_conf = check_trendline_confluence(df_m1, pb_high, pb_low, "PUT", atr_val)
                lt_confluence = float(lt_conf.get("confluence", 0.0))
                has_lt = lt_conf.get("has_trendline", False)

                # S/R PROXIMITY (estilo Candle Mind) - pullback tocou resistência?
                sr_info = sr_proximity_score(df_m1, atr_val, "PUT", pb_high, pb_low)
                sr_bonus = float(sr_info["sr_bonus"])
                sr_proximity = float(sr_info["sr_proximity"])
                sr_touches = int(sr_info["sr_touches"])

                score = 0.40  # Base aumentada

                impulso_score = min(0.12, (size_A / atr_val - IMPULSO_MIN_ATR) * 0.06)
                score += impulso_score

                eff_score = min(0.15, max(0, (eff_A - MIN_EFF_A) * 0.35))
                score += eff_score

                if 0.30 <= retr <= 0.50:
                    retr_score = 0.12
                elif 0.25 <= retr <= 0.60:
                    retr_score = 0.05
                else:
                    retr_score = max(-0.08, -(abs(retr - 0.40) * 0.20))
                score += retr_score

                if 2 <= pb_len <= 4:
                    pb_score = 0.06
                elif pb_len == 1 or pb_len == 5:
                    pb_score = 0.02
                else:
                    pb_score = -0.02
                score += pb_score

                if flips_frac > 0.50:
                    chop_penalty = min(0.20, (flips_frac - 0.50) * 0.50)
                    score -= chop_penalty

                # Contexto de mercado - MUITO IMPORTANTE
                if market_quality > 0.65:
                    ctx_score = 0.22
                elif market_quality > 0.55:
                    ctx_score = 0.12
                elif market_quality > 0.45:
                    ctx_score = 0.0
                else:
                    ctx_score = -0.30  # Penalidade SEVERA para contexto ruim
                score += ctx_score

                trend_score = min(0.08, trend_strength * 0.12)
                score += trend_score

                if entry_confidence > 0.65:
                    entry_score = 0.25
                elif entry_confidence > 0.55:
                    entry_score = 0.15
                elif entry_confidence > 0.48:
                    entry_score = 0.08
                else:
                    entry_score = -0.05
                score += entry_score

                momentum_score = min(0.10, entry_momentum * 0.08)
                score += momentum_score

                if entry_alignment >= 0.67:
                    align_score = 0.08
                elif entry_alignment >= 0.34:
                    align_score = 0.03
                else:
                    align_score = -0.03
                score += align_score

                if has_lt and lt_confluence > 0.8:
                    score += 0.25
                elif has_lt and lt_confluence > 0.5:
                    score += 0.15
                elif has_lt and lt_confluence > 0.2:
                    score += 0.05

                # BONUS S/R PROXIMITY (Candle Mind style) - resistência forte
                score += sr_bonus

                if risk_atr > 1.3:
                    risk_penalty = 0.10
                elif risk_atr > 1.0:
                    risk_penalty = 0.05
                elif risk_atr < 0.30:
                    risk_penalty = 0.05
                else:
                    risk_penalty = 0.0
                score -= risk_penalty

                perfect_count = 0
                if market_quality > 0.60: perfect_count += 1
                if eff_A > 0.70: perfect_count += 1
                if 0.30 <= retr <= 0.50: perfect_count += 1
                if entry_confidence > 0.65: perfect_count += 1
                if entry_alignment >= 0.67: perfect_count += 1
                if lt_confluence > 0.8: perfect_count += 1
                if sr_proximity > 0.50 and sr_touches >= 3: perfect_count += 1  # S/R confluência

                if perfect_count >= 5:
                    confluence_bonus = 0.20
                elif perfect_count >= 4:
                    confluence_bonus = 0.12
                elif perfect_count >= 3:
                    confluence_bonus = 0.05
                else:
                    confluence_bonus = 0.0

                score += confluence_bonus
                score = float(max(0.0, min(0.95, score)))

                # Filtros baseados no modo de operação
                if IA_MODE == "learning":
                    # Modo LEARNING: IA entende o cenário e decide
                    # Score mínimo baixo - IA aprende com entradas reais
                    if score < 0.42:
                        continue
                    # Contexto: só bloqueia se MUITO ruim
                    if market_quality < 0.25:
                        continue
                    # Confiança mínima relaxada
                    if entry_confidence < 0.35:
                        continue
                else:
                    # Modo STRICT: filtros rigorosos
                    if score < 0.60:
                        continue
                    if market_quality < 0.45:
                        continue
                    if entry_confidence < 0.50:
                        continue

                setup = {
                    "trade": True, "dir": "PUT", "score": score,
                    "pb_len": pb_len, "retr": float(retr),
                    "A_atr": float(size_A / max(atr_val, 1e-9)),
                    "effA": float(eff_A),
                    "flips": float(flips_frac),
                    "comp": float(comp),
                    "late": float(late_ext),
                    "distBreak": float(dist),
                    "market_quality": float(market_quality),
                    "context": str(context.get("context", "?")),
                    "confluence_bonus": float(confluence_bonus),
                    "trend_strength": float(trend_strength),
                    "trend_reason": str(trend_validation.get("reason", "?")),
                    "entry_confidence": float(entry_confidence),
                    "entry_momentum": float(entry_momentum),
                    "entry_alignment": float(entry_alignment),
                    "risk_atr": float(risk_atr),
                    "lt_confluence": float(lt_confluence),
                    "has_lt": has_lt,
                    "sr_proximity": float(sr_proximity),
                    "sr_bonus": float(sr_bonus),
                    "sr_touches": int(sr_touches),
                    "sr_reason": str(sr_info.get("sr_reason", "sem_sr")),
                    "reasons": [
                        "pernadaB_PUT",
                        f"A={size_A/atr_val:.2f}ATR", f"retr={retr:.2f}", f"pb={pb_len}",
                        f"effA={eff_A:.2f}",
                        f"ctx={context.get('context','?')}({market_quality:.2f})",
                        f"entry_conf={entry_confidence:.2f}",
                        f"LTB={lt_confluence:.2f}" if has_lt else "sem_LTB",
                        f"SR={sr_info.get('sr_reason','sem_sr')}" if sr_proximity > 0 else "sem_SR"
                    ]
                }

            if best is None or setup["score"] > best["score"]:
                best = setup

    if best is None:
        return {"trade": False, "dir": "NEUTRAL", "score": 0.0, "reasons": ["sem_pernadaB_valida"]}

    # Bloqueio SR final (desabilitado no modo learning)
    if IA_MODE != "learning":
        block_final = sr_block_directional_multi(df_m1, atr_val, best["dir"])
        if block_final:
            return {"trade": False, "dir": "NEUTRAL", "score": 0.0, "reasons": [block_final]}

    return best

# ===================== ESCOLHER MELHOR SETUP DO MINUTO (TODOS OS ATIVOS) =====================
def escolher_melhor_setup(iq: BrokerAPI, ativos: List[str]):
    """
    Analisa TODOS os ativos de uma vez e retorna o melhor setup.
    Se encontrar sinal confirmado em qualquer ativo, entra.
    """
    best_trade = None
    best_any = None
    
    log.info(paint(f"Analisando {len(ativos)} ativos...", C.B))

    for a in ativos:
        if a in cooldown and (time.time() - cooldown[a]) < COOLDOWN_ATIVO:
            continue
        if a in cooldown_spike and (time.time() - cooldown_spike[a]) < (SPIKE_COOLDOWN_MIN * 60):
            continue
        # Cooldown especial após LOSS no ativo
        if a in cooldown_loss and (time.time() - cooldown_loss[a]) < COOLDOWN_LOSS_ATIVO:
            continue
        # Bloquear ativo com muitos losses consecutivos
        if consecutive_losses.get(a, 0) >= MAX_CONSECUTIVE_LOSS:
            continue

        df = get_candles_df(iq, a, TF_M1, N_M1, end_ts=end_ts_closed(TF_M1))
        if df is None:
            continue

        atr_val = atr(df, 14)
        last_closed = df.iloc[-1]

        if is_spike_wicky(last_closed, atr_val):
            cooldown_spike[a] = time.time()
            continue

        setup = pernada_b(df, atr_val)

        sc_any = float(setup.get("score", 0.0))
        cand_any = (sc_any, a, setup, float(atr_val))
        if best_any is None or cand_any[0] > best_any[0]:
            best_any = cand_any

        if setup.get("trade"):
            cand_trade = (float(setup["score"]), a, setup, float(atr_val))
            if best_trade is None or cand_trade[0] > best_trade[0]:
                best_trade = cand_trade
                log.info(paint(f"  🎯 {a}: {setup['dir']} score={setup['score']:.2f}", dir_color(setup['dir'])))

    return best_trade, best_any

# ===================== ORDEM =====================
def enviar_ordem(iq: BrokerAPI, ativo: str, direcao: str, stake: float) -> Optional[Tuple[str, int]]:
    d = "call" if direcao == "CALL" else "put"
    valor = float(max(VALOR_MINIMO, stake))

    # TURBO
    try:
        ok, op_id = safe_call(iq, iq.buy, valor, ativo, d, int(EXP_FIXA))
        if ok and op_id:
            return ("turbo", int(op_id))
        log.warning(paint(f"[ORDEM-FAIL] TURBO ok={ok} op_id={op_id}", C.Y))
    except Exception as e:
        log.warning(paint(f"[ORDEM-EXC] TURBO {e}", C.Y))

    # DIGITAL
    try:
        ok, op_id = safe_call(iq, iq.buy_digital_spot, ativo, valor, d, int(EXP_FIXA))
        if ok and op_id:
            return ("digital", int(op_id))
        log.warning(paint(f"[ORDEM-FAIL] DIGITAL ok={ok} op_id={op_id}", C.Y))
    except Exception as e:
        log.warning(paint(f"[ORDEM-EXC] DIGITAL {e}", C.Y))

    return None

def wait_result(iq: BrokerAPI, op_type: str, op_id: int) -> float:
    while True:
        try:
            if op_type == "turbo":
                ok, res = safe_call(iq, iq.check_win_v4, op_id)
                if ok:
                    return float(res)
            else:
                res = safe_call(iq, iq.check_win_digital_v2, op_id)
                if isinstance(res, (int, float)):
                    return float(res)
        except Exception:
            ensure_connected(iq)
        time.sleep(0.25)

# ===================== BACKTEST AUTOMÁTICO =====================
# Arquivo para salvar estado do auto-tuner
AUTO_TUNER_FILE = os.path.join(os.path.dirname(__file__), "auto_tuner_state.json")

def backtest_antes_de_operar(iq: BrokerAPI, ativos: List[str], n_candles: int = 90) -> Dict[str, Any]:
    """
    Executa backtest nos últimos N minutos para calibrar filtros automaticamente.
    CALCULA FILTROS INDIVIDUAIS POR ATIVO!
    
    Retorna:
        {
            "sinais": int,
            "wins": int,
            "losses": int,
            "taxa_acerto": float,
            "calibrado": bool,
            "ajustes": list,
            "filtros_por_ativo": dict
        }
    """
    global GATE_CONTEXT_VERY_BAD, GATE_MIN_SCORE, filtros_por_ativo
    
    log.info("=" * 60)
    log.info(paint("🧠 BACKTEST INTELIGENTE - Analisando padrões dos últimos 90min...", C.G))
    log.info(paint("   📊 Calculando filtros INDIVIDUAIS por ativo!", C.B))
    log.info("=" * 60)
    
    # pernada_b exige MÍNIMO 150 velas agora (otimizado)
    candles_necessarios = max(200, n_candles)
    
    # Guardar filtros originais
    ctx_original = GATE_CONTEXT_VERY_BAD
    score_original = GATE_MIN_SCORE
    
    # ===== FASE 1: COLETAR TODOS OS SINAIS POR ATIVO =====
    log.info(paint("📊 Fase 1: Coletando sinais por ativo...", C.B))
    sinais_por_ativo: Dict[str, List[Dict]] = {}
    _bt_start = time.time()
    _BT_TIMEOUT = 120  # maximo 2 min para backtest inteiro
    _bt_timed_out = False
    
    for ativo in ativos[:5]:  # max 5 ativos (otimizado)
        if time.time() - _bt_start > _BT_TIMEOUT:
            log.warning(paint(f"Backtest timeout ({_BT_TIMEOUT}s) - usando dados ja coletados", C.Y))
            break
        sinais_por_ativo[ativo] = []
        try:
            log.info(f"   Buscando candles de {ativo}...")
            df = get_candles_df(iq, ativo, TF_M1, candles_necessarios + 50, min_candles=150)
            if df is None or len(df) < 160:
                continue
            
            for i in range(160, len(df) - 2, 2):  # step=2 para performance, pernada_b só precisa de 150
                df_window = df.iloc[:i].copy().reset_index(drop=True)
                
                atr_val = atr(df_window, 14)
                if atr_val < 1e-9:
                    continue
                
                setup = pernada_b(df_window, atr_val)
                
                if setup.get("trade"):
                    score = setup.get("score", 0)
                    ctx = setup.get("market_quality", 0)
                    direcao = setup.get("dir")
                    effA = setup.get("effA", 0)
                    has_lt = setup.get("has_lt", False)
                    retr = setup.get("retracement", 0.5)
                    pb = setup.get("pullback_candles", 2)
                    entry_conf = setup.get("entry_confirmation", 0.5)
                    lt_conf = setup.get("lt_confluence", 0)
                    
                    # Simular resultado
                    vela_entrada = df.iloc[i]
                    vela_resultado = df.iloc[i + 1]
                    
                    if direcao == "CALL":
                        win = vela_resultado["close"] > vela_entrada["open"]
                    else:
                        win = vela_resultado["close"] < vela_entrada["open"]
                    
                    sinais_por_ativo[ativo].append({
                        "ativo": ativo,
                        "direcao": direcao,
                        "score": score,
                        "ctx": ctx,
                        "effA": effA,
                        "has_lt": has_lt,
                        "retr": retr,
                        "pb": pb,
                        "entry_conf": entry_conf,
                        "lt_conf": lt_conf,
                        "win": win
                    })
        except Exception:
            continue
    
    # Combinar todos os sinais para análise global
    todos_sinais = []
    for ativo, sinais in sinais_por_ativo.items():
        todos_sinais.extend(sinais)
    
    total_raw = len(todos_sinais)
    if total_raw == 0:
        log.warning(paint("⚠️ Nenhum sinal encontrado no período - usando filtros relaxados", C.Y))
        GATE_CONTEXT_VERY_BAD = 0.30
        GATE_MIN_SCORE = 0.42
        # Inicializar todos os ativos como habilitados com filtros relaxados
        for ativo in ativos:
            filtros_por_ativo[ativo] = {"min_ctx": 0.30, "min_score": 0.42, "taxa": 0.50, "sinais": 0, "habilitado": True}
        return {"sinais": 0, "wins": 0, "losses": 0, "taxa_acerto": 0, "calibrado": True, "ajustes": [], "filtros_por_ativo": filtros_por_ativo, "use_trendline": False}
    
    wins_raw = sum(1 for s in todos_sinais if s["win"])
    taxa_raw = wins_raw / total_raw
    log.info(f"   Total de sinais: {total_raw} | WINs: {wins_raw} ({taxa_raw*100:.1f}%)")
    
    # ===== ANÁLISE DE TRENDLINE (has_lt) =====
    # Verificar se exigir trendline realmente melhora os resultados
    sinais_com_lt = [s for s in todos_sinais if s.get("has_lt", False)]
    sinais_sem_lt = [s for s in todos_sinais if not s.get("has_lt", False)]
    
    winrate_com_lt = sum(1 for s in sinais_com_lt if s["win"]) / len(sinais_com_lt) if sinais_com_lt else 0
    winrate_sem_lt = sum(1 for s in sinais_sem_lt if s["win"]) / len(sinais_sem_lt) if sinais_sem_lt else 0
    
    # Decidir se usa filtro de trendline automaticamente
    use_trendline_filter = False
    if len(sinais_com_lt) >= 3:
        # Se trendline melhora significativamente (>5%), usar
        if winrate_com_lt > winrate_sem_lt + 0.05:
            use_trendline_filter = True
            log.info(paint(f"   📈 Trendline ATIVADO: com_LT={winrate_com_lt*100:.0f}% ({len(sinais_com_lt)}) vs sem_LT={winrate_sem_lt*100:.0f}% ({len(sinais_sem_lt)})", C.G))
        else:
            use_trendline_filter = False
            log.info(paint(f"   📊 Trendline DESATIVADO: com_LT={winrate_com_lt*100:.0f}% vs sem_LT={winrate_sem_lt*100:.0f}% (diferença <5%)", C.Y))
    else:
        # Poucos sinais com trendline - não exigir
        use_trendline_filter = False
        log.info(paint(f"   ⚠️ Trendline DESATIVADO: poucos sinais com LT ({len(sinais_com_lt)})", C.Y))
    
    # ===== FASE 2: ANALISAR PADRÕES WINs vs LOSSes =====
    log.info(paint("🔍 Fase 2: Analisando padrões de WIN vs LOSS...", C.B))
    
    wins_list = [s for s in todos_sinais if s["win"]]
    losses_list = [s for s in todos_sinais if not s["win"]]
    
    if wins_list:
        avg_ctx_win = sum(s["ctx"] for s in wins_list) / len(wins_list)
        avg_score_win = sum(s["score"] for s in wins_list) / len(wins_list)
        min_ctx_win = min(s["ctx"] for s in wins_list)
        min_score_win = min(s["score"] for s in wins_list)
        log.info(f"   📗 WINs: ctx_médio={avg_ctx_win:.2f} score_médio={avg_score_win:.2f}")
    else:
        avg_ctx_win, avg_score_win = 0.40, 0.50
        min_ctx_win, min_score_win = 0.30, 0.42
    
    if losses_list:
        avg_ctx_loss = sum(s["ctx"] for s in losses_list) / len(losses_list)
        avg_score_loss = sum(s["score"] for s in losses_list) / len(losses_list)
        log.info(f"   📕 LOSSes: ctx_médio={avg_ctx_loss:.2f} score_médio={avg_score_loss:.2f}")
    else:
        avg_ctx_loss, avg_score_loss = 0.40, 0.55
    
    # ===== FASE 3: CALCULAR PONTO DE CORTE IDEAL =====
    log.info(paint("🎯 Fase 3: Calculando filtros ideais...", C.B))
    
    # Se taxa já está boa (≥55%), não precisa filtrar muito
    if taxa_raw >= 0.55:
        log.info(paint(f"   ✅ Taxa já está boa ({taxa_raw*100:.1f}%) - usando filtros leves", C.G))
        ctx_ideal = max(0.25, min_ctx_win - 0.08)
        score_ideal = max(0.40, min_score_win - 0.08)
    else:
        log.info(f"   🔧 Taxa baixa ({taxa_raw*100:.1f}%) - calculando ponto de corte...")
        
        # Verificar se contexto/score realmente diferenciam WINs de LOSSes
        diff_ctx = avg_ctx_win - avg_ctx_loss
        diff_score = avg_score_win - avg_score_loss
        
        # Contexto
        if diff_ctx > 0.05:  # WINs têm contexto significativamente maior
            ctx_ideal = avg_ctx_loss + (diff_ctx * 0.3)  # 30% da diferença acima do LOSS
            log.info(f"      Contexto diferencia: +{diff_ctx:.2f} → ctx≥{ctx_ideal:.2f}")
        else:
            ctx_ideal = 0.30  # Contexto não diferencia bem, usar padrão relaxado
            log.info(f"      Contexto similar (diff={diff_ctx:.2f}) → usando padrão relaxado")
        
        # Score - usar o MÍNIMO score dos WINs como referência
        score_ideal = max(0.40, min_score_win - 0.18)  # 18% abaixo do mínimo WIN
        log.info(f"      Score mínimo WIN={min_score_win:.2f} → usando {score_ideal:.2f}")
    
    # Limitar aos ranges permitidos - ULTRA RELAXADOS para permitir entradas
    ctx_ideal = max(0.25, min(0.45, ctx_ideal))
    score_ideal = max(0.40, min(0.52, score_ideal))  # Max 0.52! Permite score≥0.40
    
    log.info(f"   📐 Ponto de corte calculado: ctx≥{ctx_ideal:.2f} score≥{score_ideal:.2f}")
    
    # ===== FASE 4: TESTAR O FILTRO CALCULADO =====
    log.info(paint("📈 Fase 4: Validando filtros calculados...", C.B))
    
    sinais_filtrados = [s for s in todos_sinais if s["ctx"] >= ctx_ideal and s["score"] >= score_ideal]
    total_filtrado = len(sinais_filtrados)
    wins_filtrado = sum(1 for s in sinais_filtrados if s["win"])
    taxa_filtrado = wins_filtrado / total_filtrado if total_filtrado > 0 else 0
    
    log.info(f"   Após filtro: {total_filtrado} sinais | {wins_filtrado} WINs ({taxa_filtrado*100:.1f}%)")
    
    # ===== FASE 5: AJUSTE FINO - SÓ APLICAR SE MELHORAR! =====
    # REGRA CRÍTICA: Se filtros pioram a taxa, NÃO usar!
    
    filtros_melhoram = taxa_filtrado >= taxa_raw - 0.05  # Tolerância de 5%
    
    if not filtros_melhoram and total_filtrado >= 3:
        # Filtros PIORARAM a taxa! Usar filtros mais leves
        log.info(paint(f"   ⚠️ FILTROS PIORARAM: {taxa_raw*100:.1f}% → {taxa_filtrado*100:.1f}%", C.Y))
        log.info(paint(f"   🔄 Relaxando filtros para não piorar taxa...", C.Y))
        
        # Testar filtros mais leves progressivamente
        for ctx_test in [0.35, 0.30, 0.25]:
            for score_test in [0.50, 0.45, 0.40]:
                sinais_test = [s for s in todos_sinais if s["ctx"] >= ctx_test and s["score"] >= score_test]
                if len(sinais_test) >= 3:
                    wins_test = sum(1 for s in sinais_test if s["win"])
                    taxa_test = wins_test / len(sinais_test)
                    
                    # Aceitar se taxa for >= taxa original ou pelo menos 50%
                    if taxa_test >= taxa_raw - 0.02 or taxa_test >= 0.50:
                        ctx_ideal = ctx_test
                        score_ideal = score_test
                        total_filtrado = len(sinais_test)
                        wins_filtrado = wins_test
                        taxa_filtrado = taxa_test
                        log.info(paint(f"   ✅ Filtros relaxados: ctx≥{ctx_ideal:.2f} score≥{score_ideal:.2f} → {taxa_filtrado*100:.1f}%", C.G))
                        filtros_melhoram = True
                        break
            if filtros_melhoram:
                break
        
        # Se ainda pior, usar taxa original SEM filtros extras
        if not filtros_melhoram:
            ctx_ideal = 0.30  # Mínimo absoluto
            score_ideal = 0.40  # Mínimo absoluto
            total_filtrado = total_raw
            wins_filtrado = wins_raw
            taxa_filtrado = taxa_raw
            log.info(paint(f"   📊 Usando filtros mínimos para preservar taxa original: {taxa_raw*100:.1f}%", C.Y))
    
    elif total_filtrado < 2 and total_raw >= 3:
        # Muito restritivo - relaxar bastante
        log.info(paint("   ⚠️ Muito restritivo - relaxando filtros...", C.Y))
        ctx_ideal = max(0.30, ctx_ideal - 0.10)
        score_ideal = max(0.40, score_ideal - 0.15)
        
        sinais_filtrados = [s for s in todos_sinais if s["ctx"] >= ctx_ideal and s["score"] >= score_ideal]
        total_filtrado = len(sinais_filtrados)
        wins_filtrado = sum(1 for s in sinais_filtrados if s["win"])
        taxa_filtrado = wins_filtrado / total_filtrado if total_filtrado > 0 else taxa_raw
        log.info(f"   Após relaxar: {total_filtrado} sinais | {wins_filtrado} WINs ({taxa_filtrado*100:.1f}%)")
    
    # ===== APLICAR FILTROS GLOBAIS =====
    GATE_CONTEXT_VERY_BAD = ctx_ideal
    GATE_MIN_SCORE = score_ideal
    
    ajustes = []
    if ctx_ideal != ctx_original:
        ajustes.append(f"Contexto: {ctx_original:.2f} → {ctx_ideal:.2f}")
    if score_ideal != score_original:
        ajustes.append(f"Score: {score_original:.2f} → {score_ideal:.2f}")
    
    # ===== FASE 6: CALCULAR FILTROS INDIVIDUAIS POR ATIVO =====
    log.info(paint("🎯 Fase 6: Calculando filtros por ativo...", C.B))
    
    for ativo, sinais in sinais_por_ativo.items():
        if len(sinais) < 2:
            # Poucos sinais - usar filtros globais mas habilitar
            filtros_por_ativo[ativo] = {
                "min_ctx": ctx_ideal,
                "min_score": score_ideal,
                "taxa": 0.50,
                "sinais": len(sinais),
                "habilitado": True,
                "motivo": "poucos_sinais"
            }
            continue
        
        wins_ativo = sum(1 for s in sinais if s["win"])
        taxa_ativo = wins_ativo / len(sinais)
        
        # Calcular filtros específicos para este ativo
        wins_list_ativo = [s for s in sinais if s["win"]]
        losses_list_ativo = [s for s in sinais if not s["win"]]
        
        if wins_list_ativo:
            min_ctx_ativo = min(s["ctx"] for s in wins_list_ativo)
            min_score_ativo = min(s["score"] for s in wins_list_ativo)
            # Usar 5% abaixo do mínimo do WIN para permitir entradas similares
            ctx_ativo = max(0.25, min_ctx_ativo - 0.08)
            score_ativo = max(0.40, min_score_ativo - 0.08)
        else:
            ctx_ativo = ctx_ideal
            score_ativo = score_ideal
        
        # Decidir se ativo está habilitado
        habilitado = True
        motivo = "ok"
        
        if taxa_ativo < BACKTEST_MIN_WINRATE:
            # Taxa baixa mas não desabilita - NÃO aumenta filtros demais para não bloquear tudo
            if taxa_ativo < 0.20:  # Só desabilita se taxa EXTREMAMENTE baixa (20%)
                habilitado = False
                motivo = f"taxa_muito_baixa_{taxa_ativo*100:.0f}%"
            else:
                # NÃO aumentar filtros - deixar o backtest global decidir
                # ctx_ativo = min(0.45, ctx_ativo + 0.02)  # Aumento MÍNIMO
                # score_ativo = min(0.55, score_ativo + 0.02)
                motivo = f"taxa_baixa_{taxa_ativo*100:.0f}%"
        
        # IMPORTANTE: Limitar min_ctx para não bloquear todos os sinais
        ctx_ativo = min(0.42, ctx_ativo)  # Máximo 0.42 para ctx
        score_ativo = min(0.50, score_ativo)  # Máximo 0.50 para score
        
        filtros_por_ativo[ativo] = {
            "min_ctx": ctx_ativo,
            "min_score": score_ativo,
            "taxa": taxa_ativo,
            "sinais": len(sinais),
            "wins": wins_ativo,
            "habilitado": habilitado,
            "motivo": motivo
        }
        
        # Log
        status = "✅" if habilitado else "⛔"
        log.info(f"   {status} {ativo}: {len(sinais)} sinais | {taxa_ativo*100:.0f}% | ctx≥{ctx_ativo:.2f} score≥{score_ativo:.2f}")
    
    # ===== RESULTADO FINAL =====
    log.info("=" * 60)
    log.info(paint(f"🎯 RESULTADO DO BACKTEST INTELIGENTE:", C.G))
    log.info(f"   Sinais analisados: {total_raw}")
    log.info(f"   Taxa original: {taxa_raw*100:.1f}%")
    log.info(f"   → Taxa com filtros: {taxa_filtrado*100:.1f}% ({total_filtrado} sinais)")
    log.info(f"   Filtros finais: ctx≥{ctx_ideal:.2f} score≥{score_ideal:.2f}")
    
    if ajustes:
        log.info(paint("   📐 Ajustes:", C.Y))
        for aj in ajustes:
            log.info(f"      • {aj}")
    
    # CONDIÇÃO REVISADA: Calibrado se taxa >= 35% - deixa a IA decidir as melhores entradas
    calibrado = (taxa_filtrado >= 0.35 and total_filtrado >= 2) or (taxa_raw >= 0.35 and total_raw >= 3)
    
    if calibrado:
        if taxa_filtrado >= 0.55:
            log.info(paint("   ✅ PRONTO PARA OPERAR!", C.G))
        else:
            log.info(paint("   ⚠️ Taxa moderada - operando com cautela", C.Y))
    else:
        log.info(paint("   ⛔ Mercado MUITO difícil - considere pausar", C.R))
    
    log.info("=" * 60)
    
    # ===== SALVAR SINAIS NO HISTÓRICO ACUMULADO =====
    if BACKTEST_USE_ACCUMULATED and todos_sinais:
        try:
            backtest_history_add_signals(todos_sinais)
            hist_stats = backtest_history_analyze()
            log.info(paint(f"📚 HISTÓRICO ACUMULADO: {hist_stats['total']} amostras | WR={hist_stats['weighted_winrate']*100:.1f}% (ponderado)", C.B))
        except Exception as e:
            log.warning(f"Erro ao salvar histórico: {e}")
    
    # ===== IA APRENDE COM O BACKTEST (ATUAL + HISTÓRICO) =====
    if AI_LEARN_FROM_BACKTEST and IA_ON:
        try:
            # Carregar stats da IA
            stats_backtest = _safe_load_json(AI_STATS_FILE)
            if stats_backtest is None:
                stats_backtest = {"meta": {"total": 0}, "arms": {}, "patterns": {}}
            
            n_learned_current = 0
            n_learned_history = 0
            
            # 1. Aprender com sinais do backtest ATUAL (peso normal)
            if todos_sinais:
                n_learned_current = ai_learn_from_backtest_batch(todos_sinais, stats_backtest)
            
            # 2. Aprender com HISTÓRICO ACUMULADO (peso temporal decrescente)
            if BACKTEST_USE_ACCUMULATED:
                n_learned_history = ai_learn_from_accumulated_history(stats_backtest)
            
            # Salvar stats atualizados
            _safe_save_json(AI_STATS_FILE, stats_backtest)
            
            # Retreinar LightGBM se tiver amostras suficientes
            if LGBM_ON and len(lgbm_data) >= LGBM_MIN_SAMPLES:
                lgbm_train()
            
            log.info(paint(f"🧠 IA APRENDEU: {n_learned_current} sinais atuais + {n_learned_history} do histórico (decay temporal)", C.G))
        except Exception as e:
            import traceback
            log.warning(f"Erro ao treinar IA com backtest: {e}")
            log.warning(f"Traceback: {traceback.format_exc()}")
    elif not IA_ON:
        log.warning(paint("⚠️ IA desligada (WS_AI_ON=0) - backtest não treina IA!", C.Y))
    
    # Salvar estado
    try:
        tuner_state = {
            "last_update": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "raw_signals": total_raw,
            "raw_accuracy": taxa_raw,
            "filtered_signals": total_filtrado,
            "filtered_accuracy": taxa_filtrado,
            "thresholds": {"min_score": GATE_MIN_SCORE, "min_context": GATE_CONTEXT_VERY_BAD},
            "analysis": {
                "avg_ctx_win": avg_ctx_win if wins_list else None,
                "avg_ctx_loss": avg_ctx_loss if losses_list else None,
                "avg_score_win": avg_score_win if wins_list else None,
                "avg_score_loss": avg_score_loss if losses_list else None
            },
            "filtros_por_ativo": {k: v for k, v in filtros_por_ativo.items()},
            "ai_learned_from_backtest": AI_LEARN_FROM_BACKTEST
        }
        with open(AUTO_TUNER_FILE, "w", encoding="utf-8") as f:
            json.dump(tuner_state, f, indent=2, ensure_ascii=False)
    except Exception:
        pass
    
    return {
        "sinais": total_filtrado,
        "wins": wins_filtrado,
        "losses": total_filtrado - wins_filtrado,
        "taxa_acerto": taxa_filtrado,
        "calibrado": calibrado,
        "ajustes": ajustes,
        "filtros_por_ativo": filtros_por_ativo,
        "use_trendline": use_trendline_filter
    }

# ===================== MAIN =====================
def main():
    iq: Optional[BrokerAPI] = None
    iq = ensure_connected(iq)

    log.info("=" * 60)
    log.info("🚀 WS_AUTO_AI — Pernada B (M1) + ENSEMBLE IA")
    log.info("=" * 60)
    log.info("✅ Analisa TODOS os ativos de uma vez")
    log.info("✅ Entra quando aparecer sinal confirmado")
    log.info("✅ IA ENSEMBLE: Bayesiano + LightGBM (Gradient Boosting)")
    log.info("=" * 60)
    
    # Mostrar modo da IA
    if IA_MODE == "learning":
        log.info(paint("🧠 MODO: LEARNING - IA tem CONTROLE TOTAL, filtros relaxados", C.G))
        log.info(paint("   → Score mínimo muito baixo, IA decide quando entrar", C.B))
        log.info(paint("   → Contexto ruim NÃO bloqueia, IA aprende sozinha", C.B))
    else:
        log.info(paint("🔒 MODO: STRICT - IA + filtros rigorosos", C.Y))
        log.info(paint("   → Score mínimo alto, filtros conservadores", C.B))

    stats = _safe_load_json(AI_STATS_FILE) if IA_ON else {"meta": {"total": 0}, "arms": {}}
    if IA_ON:
        log.info(f"[BAYES] ON | file={AI_STATS_FILE} | min_samples={AI_MIN_SAMPLES} | min_prob={AI_MIN_PROB:.2f}")
    
    # Carregar LightGBM
    if LGBM_ON:
        lgbm_load_data()
        lgbm_load_model()
        log.info(paint(f"[LGBM] ON | mode={ENSEMBLE_MODE} | min_prob={LGBM_MIN_PROB:.2f} | samples={len(lgbm_data)}", C.B))
        if len(lgbm_data) >= LGBM_MIN_SAMPLES and lgbm_model is None:
            lgbm_train()
        # Mostrar status de confiabilidade
        if lgbm_reliable:
            log.info(paint(f"[LGBM] ✅ Modelo CONFIÁVEL (Val={lgbm_val_accuracy:.1f}%)", C.G))
        else:
            log.info(paint(f"[LGBM] ⚠️ Modelo NÃO confiável → usando APENAS Bayes até melhorar", C.Y))
    else:
        log.info("[LGBM] OFF - usando apenas Bayesiano")
    
    # Carregar histórico de backtest acumulado
    if BACKTEST_USE_ACCUMULATED:
        backtest_history_load()
        hist_stats = backtest_history_analyze()
        if hist_stats["total"] > 0:
            log.info(paint(f"📚 HISTÓRICO CARREGADO: {hist_stats['total']} amostras | WR={hist_stats['winrate']*100:.1f}% | WR_ponderado={hist_stats['weighted_winrate']*100:.1f}%", C.G))
        else:
            log.info(paint("📚 HISTÓRICO: Vazio (será preenchido com backtests)", C.B))
    
    # Modo de operação após LOSS
    if BACKTEST_ON_LOSS:
        log.info(paint(f"🔄 MODO: BACKTEST ON LOSS - Após LOSS faz backtest 30min, recalibra filtros e continua", C.G))
    elif RETRAIN_ON_LOSS:
        log.info(paint(f"🔄 MODO: RETRAIN & CONTINUE - Após LOSS pausa {PAUSE_AFTER_LOSS_SECONDS}s, retreina e continua", C.G))
    else:
        log.info(paint("⏹️ MODO: STOP após LOSS - Bot para e precisa reiniciar manualmente", C.Y))

    # IA aprende com backtest
    if AI_LEARN_FROM_BACKTEST:
        mode_hist = "+ HISTÓRICO ACUMULADO" if BACKTEST_USE_ACCUMULATED else ""
        log.info(paint(f"🧠 IA APRENDE COM BACKTEST: ON | peso={AI_BACKTEST_WEIGHT:.1f}x {mode_hist}", C.G))
    else:
        log.info(paint("🧠 IA aprende apenas com trades reais", C.B))

    try:
        saldo_inicial = float(iq.get_balance())
        log.info(paint(f"💰 SALDO INICIAL: {saldo_inicial:.2f} | META: {META_LUCRO_PERCENT:.1f}% (={saldo_inicial * META_LUCRO_PERCENT / 100:.2f})", C.G))
        if USE_DYNAMIC_STAKE:
            log.info(paint(f"📊 GESTÃO: {PERCENT_BANCA:.1f}% da banca por operação (stake dinâmico)", C.B))
        else:
            log.info(paint(f"📊 GESTÃO: Stake fixo de {STAKE_FIXA:.2f}", C.B))
    except Exception:
        saldo_inicial = 1000.0

    total = 0
    wins = 0

    # ========== BACKTEST INTELIGENTE ANTES DE OPERAR ==========
    mercado_ok = True  # Flag para indicar se o mercado está bom
    ultima_verificacao_mercado = time.time()
    INTERVALO_REVERIFICACAO = 120  # Re-verificar mercado a cada 2 minutos se estiver ruim
    mercado_tentativas_falhas = 0  # Contador de re-verificações que falharam
    
    # Variável global para controlar filtro de trendline dinamicamente
    global USE_TRENDLINE_FILTER, ativos_analisados_backtest
    consecutive_skips = 0  # Contador de skips consecutivos para auto-relax
    
    try:
        ativos_backtest = obter_top_ativos_otc(iq)
        if ativos_backtest:
            backtest_result = backtest_antes_de_operar(iq, ativos_backtest, n_candles=90)
            taxa_backtest = backtest_result.get("taxa_acerto", 0.0)
            
            # IMPORTANTE: Salvar quais ativos foram analisados no backtest
            ativos_analisados_backtest = list(ativos_backtest)
            
            # Atualizar USE_TRENDLINE_FILTER baseado no backtest
            USE_TRENDLINE_FILTER = backtest_result.get("use_trendline", REQUIRE_TRENDLINE)
            lt_status = "ATIVADO" if USE_TRENDLINE_FILTER else "DESATIVADO"
            log.info(paint(f"📊 Filtro de Trendline: {lt_status} (automático pelo backtest)", C.B))
            
            # Mostrar filtros finais que serão usados
            log.info(paint(f"🎯 FILTROS ATIVOS: ctx≥{GATE_CONTEXT_VERY_BAD:.2f} score≥{GATE_MIN_SCORE:.2f}", C.G))
            
            if taxa_backtest < BACKTEST_MIN_WINRATE:
                # Em vez de bloquear totalmente, operar com cautela extra
                mercado_ok = True  # PERMITIR operar mesmo com mercado difícil
                log.warning(paint(f"⚠️ MERCADO DIFÍCIL: Taxa do backtest: {taxa_backtest*100:.1f}% - OPERANDO com filtros adaptativos", C.Y))
                log.info(paint("   → IA vai selecionar APENAS os melhores sinais disponíveis", C.B))
            elif backtest_result["calibrado"]:
                log.info(paint("✅ Filtros otimizados - iniciando operações!", C.G))
            else:
                log.info(paint("⚠️ Mercado difícil mas filtros calibrados - operando com cautela", C.Y))
    except Exception as e:
        log.warning(f"Erro no backtest inicial: {e}")
    # =========================================================

    while True:
        iq = ensure_connected(iq)

        try:
            saldo_atual = float(iq.get_balance())
            deve_parar, lucro_percent = verificar_meta_atingida(saldo_inicial, saldo_atual)
            if deve_parar:
                lucro_abs = saldo_atual - saldo_inicial
                if lucro_percent >= META_LUCRO_PERCENT:
                    log.info(paint(f"🎯 META ATINGIDA! Lucro: {lucro_abs:.2f} ({lucro_percent:.2f}%) | Parando operação.", C.G))
                else:
                    log.info(paint(f"🛑 STOP LOSS! Perda: {lucro_abs:.2f} ({lucro_percent:.2f}%) | Parando operação.", C.R))
                break
        except Exception as e:
            log.warning(f"Erro ao verificar meta: {e}")

        # ========== VERIFICAR SE O MERCADO ESTÁ BOM ==========
        if not mercado_ok:
            # Re-verificar mercado periodicamente
            if time.time() - ultima_verificacao_mercado >= INTERVALO_REVERIFICACAO:
                log.info(paint("🔄 Re-verificando condições do mercado...", C.B))
                try:
                    ativos_reverif = obter_top_ativos_otc(iq)
                    if ativos_reverif:
                        backtest_reverif = backtest_antes_de_operar(iq, ativos_reverif, n_candles=90)
                        taxa_reverif = backtest_reverif.get("taxa_acerto", 0.0)
                        ultima_verificacao_mercado = time.time()
                        
                        # IMPORTANTE: Atualizar ativos analisados
                        ativos_analisados_backtest.clear()
                        ativos_analisados_backtest.extend(ativos_reverif)
                        
                        # Atualizar USE_TRENDLINE_FILTER com resultado do backtest
                        USE_TRENDLINE_FILTER = backtest_reverif.get("use_trendline", REQUIRE_TRENDLINE)
                        lt_status = "ATIVADO" if USE_TRENDLINE_FILTER else "DESATIVADO"
                        log.info(paint(f"📊 Filtro de Trendline: {lt_status}", C.B))
                        
                        if taxa_reverif >= BACKTEST_MIN_WINRATE:
                            mercado_ok = True
                            mercado_tentativas_falhas = 0
                            log.info(paint(f"✅ MERCADO MELHOROU! Taxa: {taxa_reverif*100:.1f}% - Retomando operações!", C.G))
                        else:
                            mercado_tentativas_falhas += 1
                            # Após 2 tentativas, forçar operação com cautela
                            if mercado_tentativas_falhas >= 2:
                                mercado_ok = True
                                log.warning(paint(f"🔄 Mercado difícil ({taxa_reverif*100:.1f}%) mas IA vai operar com os melhores sinais", C.Y))
                                log.info(paint("   → Filtros adaptativos ativados - IA seleciona apenas sinais fortes", C.B))
                            else:
                                log.warning(paint(f"⚠️ Mercado ainda difícil: {taxa_reverif*100:.1f}% - próxima verificação em {INTERVALO_REVERIFICACAO//60} min", C.Y))
                except Exception as e:
                    log.warning(f"Erro ao re-verificar mercado: {e}")
            
            # Se mercado não está ok, esperar
            if not mercado_ok:
                time.sleep(60)  # Esperar 1 min antes de verificar novamente
                continue
        # =====================================================

        ativos = obter_top_ativos_otc(iq)
        if not ativos:
            log.warning("Sem ativos com payout mínimo. Tentando em 10s...")
            time.sleep(10)
            continue

        # ===================== VERIFICAR NOVOS ATIVOS =====================
        # Detectar se há ativos novos que não foram analisados no backtest
        novos_ativos = [a for a in ativos if a not in ativos_analisados_backtest]
        if novos_ativos:
            log.info(paint(f"🔄 {len(novos_ativos)} NOVOS ATIVOS detectados: {novos_ativos[:3]}...", C.Y))
            log.info(paint("   → Fazendo backtest nos novos ativos antes de operar...", C.B))
            try:
                backtest_novos = backtest_antes_de_operar(iq, novos_ativos, n_candles=90)
                # Adicionar aos ativos já analisados
                ativos_analisados_backtest.extend(novos_ativos)
                log.info(paint(f"✅ Backtest concluído para novos ativos | Taxa: {backtest_novos.get('taxa_acerto', 0)*100:.1f}%", C.G))
            except Exception as e:
                log.warning(f"Erro ao fazer backtest em novos ativos: {e}")
                # Mesmo com erro, adiciona para não ficar em loop
                ativos_analisados_backtest.extend(novos_ativos)
        # ===================================================================

        wait_until_minus(TF_M1, DECIDIR_ANTES_FECHAR_SEC)

        best_trade, best_any = escolher_melhor_setup(iq, ativos)

        if not best_trade:
            if best_any:
                sc, at, st, _av = best_any
                log.info(paint(
                    f"[SKIP] nenhum setup passou | melhor={at} score={sc:.2f} | {','.join(st.get('reasons', []))}",
                    C.Y
                ))
                cooldown[at] = time.time()
            else:
                log.info(paint("[SKIP] nenhum ativo analisável no minuto", C.Y))

            wait_for_next_open(TF_M1)
            continue

        score, ativo, setup, atr_val = best_trade
        score = float(score)

        # ===================== FILTROS POR ATIVO =====================
        # Verificar se ativo está habilitado e usar filtros específicos
        if ativo in filtros_por_ativo:
            filtro_ativo = filtros_por_ativo[ativo]
            
            # Verificar se ativo está desabilitado
            if not filtro_ativo.get("habilitado", True):
                log.info(paint(
                    f"[ATIVO-SKIP] {ativo} DESABILITADO | {filtro_ativo.get('motivo', '?')} | sinais={filtro_ativo.get('sinais', 0)}",
                    C.R
                ))
                consecutive_skips += 1
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            
            # Usar filtros específicos do ativo
            min_score_ativo = filtro_ativo.get("min_score", GATE_MIN_SCORE)
            min_ctx_ativo = filtro_ativo.get("min_ctx", GATE_CONTEXT_VERY_BAD)
            ctx = setup.get("market_quality", 0)
            
            if ctx < min_ctx_ativo:
                log.info(paint(
                    f"[CTX-SKIP] {ativo} | ctx={ctx:.2f}<{min_ctx_ativo:.2f} (específico) | score={score:.2f}",
                    C.Y
                ))
                consecutive_skips += 1
                # Auto-relax: se muitos skips por CTX, reduzir min_ctx do ativo
                if AUTO_RELAX_ON_SKIPS and consecutive_skips >= MAX_CONSECUTIVE_SKIPS:
                    filtro_ativo["min_ctx"] = max(0.25, filtro_ativo["min_ctx"] - 0.05)
                    consecutive_skips = 0
                    log.info(paint(f"🔄 AUTO-RELAX: Reduzindo min_ctx de {ativo} para {filtro_ativo['min_ctx']:.2f}", C.G))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            
            if score < min_score_ativo:
                log.info(paint(
                    f"[SCORE-SKIP] {ativo} | score={score:.2f}<{min_score_ativo:.2f} (específico)",
                    C.Y
                ))
                consecutive_skips += 1
                # Auto-relax: se muitos skips por SCORE, reduzir min_score do ativo
                if AUTO_RELAX_ON_SKIPS and consecutive_skips >= MAX_CONSECUTIVE_SKIPS:
                    filtro_ativo["min_score"] = max(0.38, filtro_ativo["min_score"] - 0.03)
                    consecutive_skips = 0
                    log.info(paint(f"🔄 AUTO-RELAX: Reduzindo min_score de {ativo} para {filtro_ativo['min_score']:.2f}", C.G))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
        else:
            # Ativo não tem filtros específicos - usar globais COM verificação de contexto
            ctx = setup.get("market_quality", 0)
            
            # Verificar contexto ANTES de tudo
            if ctx < GATE_CONTEXT_VERY_BAD:
                log.info(paint(
                    f"[CTX-SKIP] {ativo} | ctx={ctx:.2f}<{GATE_CONTEXT_VERY_BAD:.2f} (global) | score={score:.2f}",
                    C.Y
                ))
                consecutive_skips += 1
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            
            if score < GATE_SOFT_SCORE:
                log.info(paint(
                    f"[SKIP] {ativo} | score={score:.2f} | {','.join(setup.get('reasons', []))}",
                    C.Y
                ))
                consecutive_skips += 1
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue

            if score < GATE_MIN_SCORE:
                log.info(paint(
                    f"[SOFT-SKIP] {ativo} | score={score:.2f} | {','.join(setup.get('reasons', []))}",
                    C.B
                ))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue

        # ===================== FILTROS DE QUALIDADE EXTRA =====================
        # Filtro 1: Exigir linha de tendência (LTA/LTB) confirmando a direção
        # Usa USE_TRENDLINE_FILTER (ajustado dinamicamente pelo backtest)
        if USE_TRENDLINE_FILTER and not setup.get("has_lt", False):
            dir_tipo = "LTA" if setup.get("dir") == "CALL" else "LTB"
            ctx_lt = setup.get("market_quality", 0)
            
            # OVERRIDE: No modo LEARNING, se score >= 0.90 E contexto bom, permite entrada sem LT
            if IA_MODE == "learning" and score >= 0.90 and ctx_lt >= 0.42:
                log.info(paint(
                    f"[LT-OVERRIDE] {ativo} | sem_{dir_tipo} mas score={score:.2f} ctx={ctx_lt:.2f} | PERMITINDO",
                    C.G
                ))
            else:
                if IA_MODE == "learning" and score >= 0.90 and ctx_lt < 0.42:
                    log.info(paint(
                        f"[LT-SKIP] {ativo} | sem_{dir_tipo} | score={score:.2f} mas ctx={ctx_lt:.2f}<0.42 (mercado ruim)",
                        C.Y
                    ))
                else:
                    log.info(paint(
                        f"[LT-SKIP] {ativo} | sem_{dir_tipo} | score={score:.2f} | {','.join(setup.get('reasons', []))}",
                        C.Y
                    ))
                # Auto-relax: se muitos skips seguidos por LT, desativar
                consecutive_skips += 1
                if AUTO_RELAX_ON_SKIPS and consecutive_skips >= MAX_CONSECUTIVE_SKIPS:
                    USE_TRENDLINE_FILTER = False
                    consecutive_skips = 0
                    log.info(paint(f"🔄 AUTO-RELAX: Desativando filtro de Trendline após {MAX_CONSECUTIVE_SKIPS} skips", C.G))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
        
        # Filtro 2: Eficiência mínima da pernada
        effA = setup.get("effA", 0.0)
        if effA < MIN_ENTRY_EFF:
            log.info(paint(
                f"[EFF-SKIP] {ativo} | effA={effA:.2f}<{MIN_ENTRY_EFF:.2f} | score={score:.2f}",
                C.Y
            ))
            wait_for_next_open(TF_M1)
            cooldown[ativo] = time.time()
            continue

        final_dir = str(setup["dir"])
        sinal_invertido = False  # Flag para não poluir IA com sinais invertidos
        
        # Info sobre filtros usados
        if ativo in filtros_por_ativo:
            filtro = filtros_por_ativo[ativo]
            filtro_info = f"[{ativo} filtros: ctx≥{filtro.get('min_ctx', 0):.2f} score≥{filtro.get('min_score', 0):.2f} taxa={filtro.get('taxa', 0)*100:.0f}%]"
            log.info(paint(filtro_info, C.B))
        
        log.info(paint(
            f"[SINAL-HARD] {ativo} -> {final_dir} | score={score:.2f} | ATR={atr_val:.6f} | {','.join(setup.get('reasons', []))}",
            dir_color(final_dir)
        ))

        if IA_ON:
            # ENSEMBLE: Combina Bayesiano + LightGBM
            ens = ensemble_predict(ativo, setup, stats)
            bayes_prob = float(ens["bayes_prob"])
            lgbm_prob = float(ens["lgbm_prob"])
            ensemble_prob = float(ens["ensemble_prob"])
            should_trade = bool(ens["should_trade"])
            ens_reason = str(ens["reason"])
            n_arm = int(ens.get("n_arm", 0))
            
            # Log do ensemble
            if LGBM_ON and lgbm_model is not None and lgbm_reliable:
                log.info(paint(
                    f"[ENSEMBLE] {ativo} {final_dir} | Bayes={bayes_prob:.2f} | LGBM={lgbm_prob:.2f} | Ens={ensemble_prob:.2f} | {ens_reason}",
                    C.B
                ))
            elif LGBM_ON and not lgbm_reliable:
                log.info(paint(
                    f"[BAYES-ONLY] {ativo} {final_dir} | prob={bayes_prob:.2f} (n={n_arm}) | LGBM desabilitado (Val={lgbm_val_accuracy:.1f}%<55%) | {ens_reason}",
                    C.Y
                ))
            else:
                log.info(paint(
                    f"[BAYES] {ativo} {final_dir} | prob={bayes_prob:.2f} (n={n_arm}) | {ens_reason}",
                    C.B
                ))
            
            # Decisão do ensemble
            if not should_trade:
                if lgbm_prob < 0.30:
                    log.info(paint(f"[IA-BLOCK] {ativo} {final_dir} | LGBM={lgbm_prob:.2f}<0.30 = PERIGO | {ens_reason}", C.R))
                else:
                    log.info(paint(f"[IA-SKIP] {ativo} {final_dir} | ensemble fraco | {ens_reason}", C.Y))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            
            # GATE EXTRA: Verificação de qualidade do contexto vs ensemble
            ctx_val = float(setup.get("market_quality", 0.40))
            entry_conf_val = float(setup.get("entry_confidence", 0.50))
            sr_prox_gate = float(setup.get("sr_proximity", 0.0))
            sr_tq_gate = int(setup.get("sr_touches", 0))
            sr_forte = sr_prox_gate > 0.50 and sr_tq_gate >= 3  # S/R forte = confiança extra
            
            if ctx_val < 0.40 and ensemble_prob < ENS_MIN_CTX_RUIM and not sr_forte:
                log.info(paint(f"[CTX-GATE] {ativo} {final_dir} | ctx_ruim={ctx_val:.2f} precisa ens>={ENS_MIN_CTX_RUIM:.2f} mas ens={ensemble_prob:.2f}", C.Y))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            if ctx_val < 0.40 and entry_conf_val < 0.50 and lgbm_prob < 0.52 and not sr_forte:
                log.info(paint(f"[CTX-GATE] {ativo} {final_dir} | ctx_ruim+entry_fraco | ctx={ctx_val:.2f},conf={entry_conf_val:.2f},L={lgbm_prob:.2f}", C.Y))
                wait_for_next_open(TF_M1)
                cooldown[ativo] = time.time()
                continue
            
            # LOG S/R quando detectado
            if sr_prox_gate > 0:
                sr_reason_log = str(setup.get("sr_reason", "?"))
                log.info(paint(f"[SR-ZONE] {ativo} {final_dir} | {sr_reason_log} | bonus={setup.get('sr_bonus',0):.2f}", C.G if sr_forte else C.B))

        wait_for_next_open(TF_M1)

        stake = calcular_stake_dinamico(iq, STAKE_FIXA)
        log.info(paint(f"[{ativo}] 💵 Stake calculado: {stake:.2f}", C.B))

        op = enviar_ordem(iq, ativo, final_dir, stake)

        if not op:
            log.error(paint(f"[{ativo}] ❌ falhou enviar ordem (TURBO/DIGITAL).", C.R))
            cooldown[ativo] = time.time()
            continue

        # Resetar contador de skips - uma operação foi feita
        consecutive_skips = 0
        
        op_type, op_id = op
        log.info(paint(
            f"[{ativo}] ✅ ORDEM ENVIADA {final_dir} exp={EXP_FIXA}m ({op_type}) | stake={stake:.2f}",
            dir_color(final_dir)
        ))

        res = wait_result(iq, op_type, op_id)

        total += 1
        global global_consecutive_losses
        
        should_pause_and_continue = False  # Flag para pausar e continuar após LOSS
        
        if res > 0:
            wins += 1
            log.info(paint(f"[{ativo}] ✅ WIN {res:.2f}$", C.G))
            # Reset counters após WIN
            consecutive_losses[ativo] = 0
            global_consecutive_losses = 0
            
            # RECOMPENSAR ATIVO QUE DEU WIN - relaxar filtros levemente
            if ativo in filtros_por_ativo:
                filtro = filtros_por_ativo[ativo]
                # Relaxar filtros levemente (mas não muito)
                filtro["min_ctx"] = max(0.35, filtro.get("min_ctx", 0.40) - 0.01)
                filtro["min_score"] = max(0.50, filtro.get("min_score", 0.55) - 0.01)
                filtro["taxa"] = min(1.0, filtro.get("taxa", 0.50) + 0.05)  # Aumentar taxa estimada
                filtro["habilitado"] = True  # Garantir que está habilitado
                filtro["motivo"] = "ok_win"
        elif res < 0:
            log.info(paint(f"[{ativo}] ❌ LOSS {res:.2f}$", C.R))
            # Incrementar contadores de LOSS
            consecutive_losses[ativo] = consecutive_losses.get(ativo, 0) + 1
            global_consecutive_losses += 1
            # Aplicar cooldown especial após LOSS
            cooldown_loss[ativo] = time.time()
            
            # PENALIZAR FILTROS DO ATIVO ESPECÍFICO QUE DEU LOSS
            if ativo in filtros_por_ativo:
                filtro = filtros_por_ativo[ativo]
                # Apertar filtros do ativo que deu LOSS
                filtro["min_ctx"] = min(0.50, filtro.get("min_ctx", 0.40) + 0.03)
                filtro["min_score"] = min(0.65, filtro.get("min_score", 0.55) + 0.03)
                filtro["taxa"] = max(0.0, filtro.get("taxa", 0.50) - 0.10)  # Reduzir taxa estimada
                
                # Se taxa ficar muito baixa, desabilitar ativo
                if filtro["taxa"] < 0.35:
                    filtro["habilitado"] = False
                    filtro["motivo"] = f"desabilitado_loss_consec_{consecutive_losses[ativo]}"
                    log.warning(paint(f"⛔ {ativo} DESABILITADO após LOSS! Taxa estimada muito baixa", C.R))
                else:
                    log.info(paint(f"🔧 {ativo} filtros apertados: ctx≥{filtro['min_ctx']:.2f} score≥{filtro['min_score']:.2f}", C.Y))
            
            # RETREINO SEVERO: aplicar penalidade extra no padrão (apenas se não usar backtest)
            if IA_ON and not BACKTEST_ON_LOSS:
                ai_retrain_on_loss(ativo, setup, stats)
                log.warning(paint(f"[RETRAIN] Padrão penalizado com {RETRAIN_PENALTY:.0%} - IA aprendendo com erro", C.Y))
            
            # BACKTEST_ON_LOSS: fazer backtest de 30 min para recalibrar filtros
            if BACKTEST_ON_LOSS:
                log.info(paint("="*60, C.Y))
                log.info(paint("🔄 RECALIBRANDO FILTROS COM BACKTEST DE 30 MINUTOS...", C.Y))
                log.info(paint("="*60, C.Y))
                try:
                    # Usar ativos atuais para o backtest pós-LOSS
                    ativos_recalibrar = obter_top_ativos_otc(iq)
                    backtest_result_loss = backtest_antes_de_operar(iq, ativos_recalibrar, n_candles=90)  # 90 candles (otimizado)
                    taxa_backtest_loss = backtest_result_loss.get("taxa_acerto", 0.0)
                    
                    # IMPORTANTE: Atualizar ativos analisados (backtest completo, não incremental)
                    ativos_analisados_backtest.clear()
                    ativos_analisados_backtest.extend(ativos_recalibrar)
                    
                    # Atualizar USE_TRENDLINE_FILTER com resultado do backtest pós-LOSS
                    USE_TRENDLINE_FILTER = backtest_result_loss.get("use_trendline", REQUIRE_TRENDLINE)
                    lt_status = "ATIVADO" if USE_TRENDLINE_FILTER else "DESATIVADO"
                    log.info(paint(f"📊 Filtro de Trendline: {lt_status}", C.B))
                    
                    # Verificar se mercado ainda está bom
                    if taxa_backtest_loss < BACKTEST_MIN_WINRATE:
                        mercado_ok = False
                        log.warning(paint(f"⛔ MERCADO RUIM APÓS LOSS! Taxa: {taxa_backtest_loss*100:.1f}% < {BACKTEST_MIN_WINRATE*100:.1f}%", C.R))
                        log.warning(paint("   → Aguardando mercado melhorar antes de continuar...", C.Y))
                    elif taxa_backtest_loss < 0.55:
                        # Mercado mediano - apertar filtros globais como proteção extra
                        mercado_ok = True
                        log.warning(paint(f"⚠️ Mercado MEDIANO após recalibração: {taxa_backtest_loss*100:.1f}% - filtros mais rigorosos", C.Y))
                    else:
                        mercado_ok = True
                        log.info(paint(f"✅ Mercado OK após recalibração: {taxa_backtest_loss*100:.1f}%", C.G))
                    ultima_verificacao_mercado = time.time()
                except Exception as e:
                    log.error(f"Erro no backtest pós-LOSS: {e}")
                should_pause_and_continue = True
                log.info(paint(f"⏳ Filtros recalibrados - pausando {PAUSE_AFTER_LOSS_SECONDS}s antes de continuar...", C.Y))
            # RETRAIN_ON_LOSS: pausar, retreinar e continuar automaticamente (fallback)
            elif RETRAIN_ON_LOSS:
                should_pause_and_continue = True
                log.warning(paint(f"[RETRAIN] IA retreinada - pausando {PAUSE_AFTER_LOSS_SECONDS}s antes de continuar", C.Y))
            elif global_consecutive_losses >= MAX_CONSECUTIVE_LOSS:
                should_pause_and_continue = True
                log.warning(paint(f"[PAUSE] {global_consecutive_losses} losses consecutivos - pausando {PAUSE_AFTER_LOSS_SECONDS}s", C.Y))
        else:
            log.info(paint(f"[{ativo}] ⚪ EMPATE {res:.2f}$", C.B))

        # Só treina IA se o sinal NÃO foi invertido (para não poluir o aprendizado)
        if sinal_invertido:
            log.info(paint(f"[🔄 NO-TRAIN] Sinal foi INVERTIDO - NÃO treinando IA com este resultado", C.Y))
        else:
            if IA_ON:
                ai_update(ativo, setup, res, stats)
                _safe_save_json(AI_STATS_FILE, stats)
            
            # Adiciona amostra ao LightGBM para aprendizado
            if LGBM_ON:
                lgbm_add_sample(setup, res)
        
        # PAUSAR e CONTINUAR automaticamente após LOSS (não para o bot)
        if should_pause_and_continue:
            # Escalar pausa com losses consecutivos: 60s, 120s, 180s...
            pause_multiplier = max(1, global_consecutive_losses)
            pause_time = min(PAUSE_AFTER_LOSS_SECONDS * pause_multiplier, 300)  # máx 5 min
            log.info(paint("=" * 60, C.Y))
            if BACKTEST_ON_LOSS:
                log.info(paint("⏸️ PAUSANDO APÓS LOSS - FILTROS RECALIBRADOS VIA BACKTEST", C.Y))
            else:
                log.info(paint("⏸️ PAUSANDO APÓS LOSS - IA RETREINADA (BAYES + LGBM)", C.Y))
            log.info(paint(f"📊 RESUMO: trades={total} wins={wins} acc={(wins/max(1,total))*100:.1f}%", C.Y))
            log.info(paint(f"⏳ Esperando {pause_time}s antes de continuar (x{pause_multiplier})...", C.Y))
            log.info(paint("=" * 60, C.Y))
            time.sleep(pause_time)
            global_consecutive_losses = 0  # Reset após pausa
            log.info(paint("\n▶️ RETOMANDO OPERAÇÕES - Filtros ajustados!\n", C.G))
            continue  # Continua o loop principal

        acc = (wins / max(1, total)) * 100.0

        try:
            saldo_atual = float(iq.get_balance())
            lucro_atual = saldo_atual - saldo_inicial
            lucro_percent_atual = (lucro_atual / saldo_inicial) * 100.0
            falta_meta = (saldo_inicial * META_LUCRO_PERCENT / 100.0) - lucro_atual

            if lucro_percent_atual >= 0:
                log.info(paint(f"📊 GLOBAL: trades={total} wins={wins} acc={acc:.2f}%", C.G))
                log.info(paint(f"💰 SALDO: {saldo_atual:.2f} | LUCRO: +{lucro_atual:.2f} ({lucro_percent_atual:.2f}%) | FALTA: {falta_meta:.2f} para meta\n", C.G))
            else:
                log.info(paint(f"📊 GLOBAL: trades={total} wins={wins} acc={acc:.2f}%", C.Y))
                log.info(paint(f"💰 SALDO: {saldo_atual:.2f} | PERDA: {lucro_atual:.2f} ({lucro_percent_atual:.2f}%)\n", C.Y))
        except Exception:
            log.info(f"📊 GLOBAL: trades={total} wins={wins} acc={acc:.2f}%\n")

        cooldown[ativo] = time.time()

if __name__ == "__main__":
    while True:
        try:
            main()
        except (RuntimeError, ConnectionError, OSError) as e:
            log.error(paint(f"❌ Bot caiu por erro de conexão: {e}", C.R))
            log.info(paint("🔄 Reiniciando em 30 segundos...", C.Y))
            time.sleep(30)
        except KeyboardInterrupt:
            log.info("Bot encerrado pelo usuário.")
            break
        except Exception as e:
            log.error(paint(f"❌ Erro inesperado: {e}", C.R))
            log.info(paint("🔄 Reiniciando em 60 segundos...", C.Y))
            time.sleep(60)
